{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e1edabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbcdb257",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = 'CMIN/CMIN-US/price/raw/BABA.csv'\n",
    "df1 = pd.read_csv(f_path)\n",
    "df1['Date'] = pd.to_datetime(df1['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a1fcba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = 'CMIN/CMIN-US/price/raw/BAC.csv'\n",
    "df2 = pd.read_csv(f_path)\n",
    "df2['Date'] = pd.to_datetime(df2['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd1404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = pd.merge(df1[['Date','Close']], df2[['Date','Close']], on='Date', how='inner', suffixes=('_BABA', '_BAC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b14068",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.set_index('Date', inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18b9e6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a82a5b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuqin\\AppData\\Local\\Temp\\ipykernel_4840\\275173771.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  merge_df['Close_BAC'] = merge_df['Close_BAC']/ merge_df['Close_BAC'][0]\n",
      "C:\\Users\\yuqin\\AppData\\Local\\Temp\\ipykernel_4840\\275173771.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  merge_df['Close_BABA'] = merge_df['Close_BABA']/ merge_df['Close_BABA'][0]\n"
     ]
    }
   ],
   "source": [
    "merge_df['Close_BAC'] = merge_df['Close_BAC']/ merge_df['Close_BAC'][0]\n",
    "merge_df['Close_BABA'] = merge_df['Close_BABA']/ merge_df['Close_BABA'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baa4259f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Date'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merge_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2af8a0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_BABA</th>\n",
       "      <th>Close_BAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Close_BABA</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.2181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close_BAC</th>\n",
       "      <td>-0.2181</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close_BABA  Close_BAC\n",
       "Close_BABA      1.0000    -0.2181\n",
       "Close_BAC      -0.2181     1.0000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55088f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtn_df = np.log(merge_df).diff(-1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f629acf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_BABA</th>\n",
       "      <th>Close_BAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Close_BABA</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.303503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close_BAC</th>\n",
       "      <td>0.303503</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close_BABA  Close_BAC\n",
       "Close_BABA    1.000000   0.303503\n",
       "Close_BAC     0.303503   1.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtn_df.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "005e6f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_BABA</th>\n",
       "      <th>Close_BAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Close_BABA</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.29358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close_BAC</th>\n",
       "      <td>0.29358</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close_BABA  Close_BAC\n",
       "Close_BABA     1.00000    0.29358\n",
       "Close_BAC      0.29358    1.00000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtn_df.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83c40c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Close_BABA</th>\n",
       "      <th>Close_BAC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2018</th>\n",
       "      <th>Close_BABA</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close_BAC</th>\n",
       "      <td>0.436550</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2019</th>\n",
       "      <th>Close_BABA</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close_BAC</th>\n",
       "      <td>0.465117</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2020</th>\n",
       "      <th>Close_BABA</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.353892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close_BAC</th>\n",
       "      <td>0.353892</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2021</th>\n",
       "      <th>Close_BABA</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.101842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close_BAC</th>\n",
       "      <td>0.101842</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Close_BABA  Close_BAC\n",
       "Date                                  \n",
       "2018 Close_BABA    1.000000   0.436550\n",
       "     Close_BAC     0.436550   1.000000\n",
       "2019 Close_BABA    1.000000   0.465117\n",
       "     Close_BAC     0.465117   1.000000\n",
       "2020 Close_BABA    1.000000   0.353892\n",
       "     Close_BAC     0.353892   1.000000\n",
       "2021 Close_BABA    1.000000   0.101842\n",
       "     Close_BAC     0.101842   1.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtn_df.groupby(rtn_df.index.year).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bf21f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Date'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merge_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d874fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL.csv', 'ABBV.csv', 'ABT.csv', 'ACN.csv', 'ADBE.csv', 'ADP.csv', 'AEP.csv', 'AMT.csv', 'AMZN.csv', 'APD.csv', 'ASML.csv', 'AVGO.csv', 'AWK.csv', 'BA.csv', 'BABA.csv', 'BAC.csv', 'BBL.csv', 'BHP.csv', 'BP.csv', 'BRK-A.csv', 'C-PJ.csv', 'CAT.csv', 'CCI.csv', 'CHTR.csv', 'CMCSA.csv', 'COP.csv', 'COST.csv', 'CSCO.csv', 'CTA-PB.csv', 'CVX.csv', 'D.csv', 'DE.csv', 'DEO.csv', 'DHR.csv', 'DIS.csv', 'DLR.csv', 'DUK.csv', 'ECL.csv', 'EL.csv', 'ENB.csv', 'EQIX.csv', 'EQNR.csv', 'EXC.csv', 'FB.csv', 'FCX.csv', 'GE.csv', 'GOOG.csv', 'HD.csv', 'HON.csv', 'JD.csv', 'JNJ.csv', 'JPM.csv', 'KO.csv', 'LLY.csv', 'LOW.csv', 'MA.csv', 'MCD.csv', 'MMM.csv', 'MS.csv', 'MSFT.csv', 'NEE.csv', 'NEM.csv', 'NFLX.csv', 'NGG.csv', 'NKE.csv', 'NVDA.csv', 'NVO.csv', 'NVS.csv', 'O.csv', 'ORCL.csv', 'PEP.csv', 'PFE.csv', 'PG.csv', 'PLD.csv', 'PM.csv', 'PSA.csv', 'PTR.csv', 'PYPL.csv', 'RDS-B.csv', 'RIO.csv', 'RTX.csv', 'SBAC.csv', 'SBUX.csv', 'SCHW.csv', 'SHW.csv', 'snap.csv', 'SNP.csv', 'SO.csv', 'SPG-PJ.csv', 'SRE.csv', 'T.csv', 'TGT.csv', 'TM.csv', 'TMO.csv', 'TMUS.csv', 'TSLA.csv', 'TSM.csv', 'TTE.csv', 'UL.csv', 'UNH.csv', 'Unp.csv', 'UPS.csv', 'V.csv', 'VALE.csv', 'VZ.csv', 'WELL.csv', 'WFC-PL.csv', 'WMT.csv', 'XEL.csv', 'XOM.csv']\n",
      "['AAPL', 'ABBV', 'ABT', 'ACN', 'ADBE', 'ADP', 'AEP', 'AMT', 'AMZN', 'APD', 'ASML', 'AVGO', 'AWK', 'BA', 'BABA', 'BAC', 'BBL', 'BHP', 'BP', 'BRK-A', 'C-PJ', 'CAT', 'CCI', 'CHTR', 'CMCSA', 'COP', 'COST', 'CSCO', 'CTA-PB', 'CVX', 'D', 'DE', 'DEO', 'DHR', 'DIS', 'DLR', 'DUK', 'ECL', 'EL', 'ENB', 'EQIX', 'EQNR', 'EXC', 'FB', 'FCX', 'GE', 'GOOG', 'HD', 'HON', 'JD', 'JNJ', 'JPM', 'KO', 'LLY', 'LOW', 'MA', 'MCD', 'MMM', 'MS', 'MSFT', 'NEE', 'NEM', 'NFLX', 'NGG', 'NKE', 'NVDA', 'NVO', 'NVS', 'O', 'ORCL', 'PEP', 'PFE', 'PG', 'PLD', 'PM', 'PSA', 'PTR', 'PYPL', 'RDS-B', 'RIO', 'RTX', 'SBAC', 'SBUX', 'SCHW', 'SHW', 'snap', 'SNP', 'SO', 'SPG-PJ', 'SRE', 'T', 'TGT', 'TM', 'TMO', 'TMUS', 'TSLA', 'TSM', 'TTE', 'UL', 'UNH', 'Unp', 'UPS', 'V', 'VALE', 'VZ', 'WELL', 'WFC-PL', 'WMT', 'XEL', 'XOM']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the directory\n",
    "directory = 'CMIN/CMIN-US/price/raw/'\n",
    "\n",
    "# List all files in the directory\n",
    "filenames = os.listdir(directory)\n",
    "\n",
    "print(filenames)\n",
    "company_list = []\n",
    "for filename in filenames:\n",
    "    filename = filename[:-4]\n",
    "    company_list.append(filename)\n",
    "print(company_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "386e32f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key='sk-Hdf6Ybl_685eMpO2-wbhke_SblUC65NaULFM2cfOkHT3BlbkFJVcE21Wnb_pHC7uBq4bbgEq8GiWNcwuoXVrc7BhIwYA')\n",
    "\n",
    "# Function to get the correlation between two companies\n",
    "def query_gpt_for_correlation(sentence):\n",
    "    systemPrompt = f\"\"\"Based on fundamental information, estimate the correlation coefficient of the following stocks. \n",
    "    You need to answer with a floating-point number between the range [-1,1], where 1 represents perfect positive correlation, -1 represents perfect negative correlation, and 0 represents no correlation.\n",
    "    For example: \n",
    "                Sample Input: [BAC, BABA]\n",
    "                Sample Output: Value: -0.22, Explanation:Bank of America (BAC) operates in the financial sector, while Alibaba (BABA) is in e-commerce and technology;BAC's performance is heavily influenced by the U.S. economy and financial markets, while BABA is more tied to the Chinese economy and global e-commerce;While both companies may react to global economic factors, their sensitivity to specific economic policies, such as interest rates or trade policies, differs.\n",
    "                Sample Input: [TSLA, AAPL]\n",
    "                Sample Output: Value: 0.25, Explanation: Both Tesla (TSLA) and Apple (AAPL) are tech-driven companies, which means they both tend to move similarly when the broader technology sector is affected by investor sentiment or market conditions;Tesla operates in the electric vehicle and renewable energy space, while Apple is focused on consumer electronics;Both stocks are high-growth companies and are often included in tech-focused investment portfolios. Positive or negative sentiment around tech stocks can lead to both moving in the same direction, contributing to a moderate correlation. \n",
    "\"\"\"\n",
    "    prompt = sentence\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": systemPrompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=1500,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b76bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list=company_list[:20]\n",
    "n_company =len(company_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ce816e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10/10 [00:05<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# from tqdm import trange\n",
    "# import time\n",
    "# test = range(10)\n",
    "# # trange demo\n",
    "# for i in trange(10):\n",
    "#     time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5968de8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [ABBV, AAPL] 0.15\n",
      "Input: [ABT, AAPL] 0.15\n",
      "Input: [ABT, ABBV] 0.67\n",
      "Input: [ACN, AAPL] 0.35\n",
      "Input: [ACN, ABBV] 0.1\n",
      "Input: [ACN, ABT] 0.15\n",
      "Input: [ADBE, AAPL] 0.65\n",
      "Input: [ADBE, ABBV] 0.15\n",
      "Input: [ADBE, ABT] 0.15\n",
      "Input: [ADBE, ACN] 0.68\n",
      "Input: [ADP, AAPL] 0.15\n",
      "Input: [ADP, ABBV] 0.15\n",
      "Input: [ADP, ABT] 0.15\n",
      "Input: [ADP, ACN] 0.6\n",
      "Input: [ADP, ADBE] 0.35\n",
      "Input: [AEP, AAPL] 0.15\n",
      "Input: [AEP, ABBV] 0.15\n",
      "Input: [AEP, ABT] 0.1\n",
      "Input: [AEP, ACN] 0.15\n",
      "Input: [AEP, ADBE] 0.15\n",
      "Input: [AEP, ADP] 0.15\n",
      "Input: [AMT, AAPL] 0.4\n",
      "Input: [AMT, ABBV] 0.15\n",
      "Input: [AMT, ABT] 0.1\n",
      "Input: [AMT, ACN] 0.35\n",
      "Input: [AMT, ADBE] 0.35\n",
      "Input: [AMT, ADP] 0.35\n",
      "Input: [AMT, AEP] 0.15\n",
      "Input: [AMZN, AAPL] 0.35\n",
      "Input: [AMZN, ABBV] 0.05\n",
      "Input: [AMZN, ABT] 0.15\n",
      "Input: [AMZN, ACN] 0.35\n",
      "Input: [AMZN, ADBE] 0.35\n",
      "Input: [AMZN, ADP] 0.15\n",
      "Input: [AMZN, AEP] -0.15\n",
      "Input: [AMZN, AMT] 0.3\n",
      "Input: [APD, AAPL] 0.15\n",
      "Input: [APD, ABBV] 0.15\n",
      "Input: [APD, ABT] 0.1\n",
      "Input: [APD, ACN] 0.15\n",
      "Input: [APD, ADBE] 0.15\n",
      "Input: [APD, ADP] 0.15\n",
      "Input: [APD, AEP] 0.15\n",
      "Input: [APD, AMT] 0.15\n",
      "Input: [APD, AMZN] 0.15\n",
      "Input: [ASML, AAPL] 0.45\n",
      "Input: [ASML, ABBV] 0.1\n",
      "Input: [ASML, ABT] 0.15\n",
      "Input: [ASML, ACN] 0.35\n",
      "Input: [ASML, ADBE] 0.35\n",
      "Input: [ASML, ADP] 0.15\n",
      "Input: [ASML, AEP] -0.15\n",
      "Input: [ASML, AMT] 0.15\n",
      "Input: [ASML, AMZN] 0.35\n",
      "Input: [ASML, APD] 0.15\n",
      "Input: [AVGO, AAPL] 0.55\n",
      "Input: [AVGO, ABBV] 0.1\n",
      "Input: [AVGO, ABT] 0.15\n",
      "Input: [AVGO, ACN] 0.45\n",
      "Input: [AVGO, ADBE] 0.35\n",
      "Input: [AVGO, ADP] 0.4\n",
      "Input: [AVGO, AEP] -0.15\n",
      "Input: [AVGO, AMT] 0.15\n",
      "Input: [AVGO, AMZN] 0.3\n",
      "Input: [AVGO, APD] 0.15\n",
      "Input: [AVGO, ASML] 0.65\n",
      "Input: [AWK, AAPL] 0.15\n",
      "Input: [AWK, ABBV] 0.1\n",
      "Input: [AWK, ABT] 0.15\n",
      "Input: [AWK, ACN] 0.15\n",
      "Input: [AWK, ADBE] 0.15\n",
      "Input: [AWK, ADP] 0.1\n",
      "Input: [AWK, AEP] 0.55\n",
      "Input: [AWK, AMT] 0.35\n",
      "Input: [AWK, AMZN] 0.15\n",
      "Input: [AWK, APD] 0.2\n",
      "Input: [AWK, ASML] 0.1\n",
      "Input: [AWK, AVGO] 0.1\n",
      "Input: [BA, AAPL] 0.15\n",
      "Input: [BA, ABBV] -0.15\n",
      "Input: [BA, ABT] 0.1\n",
      "Input: [BA, ACN] 0.15\n",
      "Input: [BA, ADBE] 0.15\n",
      "Input: [BA, ADP] 0.1\n",
      "Input: [BA, AEP] -0.15\n",
      "Input: [BA, AMT] -0.15\n",
      "Input: [BA, AMZN] -0.1\n",
      "Input: [BA, APD] 0.15\n",
      "Input: [BA, ASML] 0.15\n",
      "Input: [BA, AVGO] 0.15\n",
      "Input: [BA, AWK] -0.15\n",
      "Input: [BABA, AAPL] 0.35\n",
      "Input: [BABA, ABBV] -0.15\n",
      "Input: [BABA, ABT] -0.15\n",
      "Input: [BABA, ACN] 0.15\n",
      "Input: [BABA, ADBE] 0.35\n",
      "Input: [BABA, ADP] -0.15\n",
      "Input: [BABA, AEP] -0.15\n",
      "Input: [BABA, AMT] -0.15\n",
      "Input: [BABA, AMZN] 0.5\n",
      "Input: [BABA, APD] -0.15\n",
      "Input: [BABA, ASML] 0.35\n",
      "Input: [BABA, AVGO] 0.35\n",
      "Input: [BABA, AWK] -0.15\n",
      "Input: [BABA, BA] 0.05\n",
      "Input: [BAC, AAPL] 0.15\n",
      "Input: [BAC, ABBV] -0.1\n",
      "Input: [BAC, ABT] -0.1\n",
      "Input: [BAC, ACN] 0.15\n",
      "Input: [BAC, ADBE] 0.15\n",
      "Input: [BAC, ADP] 0.45\n",
      "Input: [BAC, AEP] 0.1\n",
      "Input: [BAC, AMT] -0.15\n",
      "Input: [BAC, AMZN] -0.15\n",
      "Input: [BAC, APD] 0.15\n",
      "Input: [BAC, ASML] 0.15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m company2 \u001b[38;5;241m=\u001b[39m company_pairs[i][\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     19\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompany\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompany2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 20\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mquery_gpt_for_correlation\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m correlation_value \u001b[38;5;241m=\u001b[39m get_value(response)\n\u001b[0;32m     22\u001b[0m correlation_value_list\u001b[38;5;241m.\u001b[39mappend(correlation_value)\n",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m, in \u001b[0;36mquery_gpt_for_correlation\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      6\u001b[0m     systemPrompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mBased on fundamental information, estimate the correlation coefficient of the following stocks. \u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m    You need to answer with a floating-point number between the range [-1,1], where 1 represents perfect positive correlation, -1 represents perfect negative correlation, and 0 represents no correlation.\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m    For example: \u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m                Sample Output: Value: 0.25, Explanation: Both Tesla (TSLA) and Apple (AAPL) are tech-driven companies, which means they both tend to move similarly when the broader technology sector is affected by investor sentiment or market conditions;Tesla operates in the electric vehicle and renewable energy space, while Apple is focused on consumer electronics;Both stocks are high-growth companies and are often included in tech-focused investment portfolios. Positive or negative sentiment around tech stocks can lead to both moving in the same direction, contributing to a moderate correlation. \u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     14\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m sentence\n\u001b[1;32m---> 15\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystemPrompt\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\openai\\_utils\\_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\openai\\resources\\chat\\completions.py:704\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    701\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    702\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    703\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\openai\\_base_client.py:1270\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1257\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1258\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1265\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1267\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1268\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1269\u001b[0m     )\n\u001b[1;32m-> 1270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\openai\\_base_client.py:947\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    945\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\openai\\_base_client.py:983\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m    980\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 983\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    984\u001b[0m         request,\n\u001b[0;32m    985\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    987\u001b[0m     )\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    989\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpcore\\_sync\\http_proxy.py:344\u001b[0m, in \u001b[0;36mTunnelHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;241m=\u001b[39m HTTP11Connection(\n\u001b[0;32m    338\u001b[0m                 origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remote_origin,\n\u001b[0;32m    339\u001b[0m                 stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    340\u001b[0m                 keepalive_expiry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keepalive_expiry,\n\u001b[0;32m    341\u001b[0m             )\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpcore\\_sync\\http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpcore\\_sync\\http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    107\u001b[0m     (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m         trailing_data,\n\u001b[1;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m         http_version,\n\u001b[0;32m    116\u001b[0m         status,\n\u001b[0;32m    117\u001b[0m         reason_phrase,\n\u001b[0;32m    118\u001b[0m         headers,\n\u001b[0;32m    119\u001b[0m     )\n\u001b[0;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpcore\\_sync\\http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define a function to extract the correlation value from the response\n",
    "def get_value(sample):\n",
    "    import re\n",
    "    pattern = r'Value: (-?\\d+\\.\\d+)'\n",
    "    match = re.search(pattern, sample)\n",
    "    value= float(match.group(1))\n",
    "    return value\n",
    "\n",
    "correlation_value_list = []\n",
    "company_pairs = []\n",
    "for i in range(n_company):\n",
    "    for j in range(i+1):\n",
    "        if i != j:\n",
    "            company_pairs.append([company_list[i], company_list[j]])\n",
    "\n",
    "for i in range(len(company_pairs)):\n",
    "    company = company_pairs[i][0]\n",
    "    company2 = company_pairs[i][1]\n",
    "    sentence = f\"Input: [{company}, {company2}]\"\n",
    "    response = query_gpt_for_correlation(sentence)\n",
    "    correlation_value = get_value(response)\n",
    "    correlation_value_list.append(correlation_value)\n",
    "    print(sentence, correlation_value)\n",
    "\n",
    "# \n",
    "import pandas as pd\n",
    "\n",
    "# CSV\n",
    "data = pd.read_csv(r'C:\\Users\\yuqin\\firsttry\\correlation_df.csv')\n",
    "\n",
    "# \n",
    "data['Company'] = data['Company'].apply(lambda x: eval(x))  # \n",
    "data['Company1'] = data['Company'].apply(lambda x: x[0])\n",
    "data['Company2'] = data['Company'].apply(lambda x: x[1])\n",
    "\n",
    "# \n",
    "matrix_df = data.pivot_table(index='Company1', columns='Company2', values='Correlation')\n",
    "\n",
    "# \n",
    "matrix_df = matrix_df.combine_first(matrix_df.T)\n",
    "\n",
    "# 11\n",
    "for company in matrix_df.columns:\n",
    "    matrix_df.loc[company, company] = 1.0\n",
    "matrix_df.to_csv(r'C:\\Users\\yuqin\\firsttry\\correlation_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e1fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct graph\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "# Create a DataFrame to store the correlation values\n",
    "correlation_df = pd.DataFrame(correlation_value_list, columns=['Correlation'])\n",
    "correlation_df['Company'] = company_pairs\n",
    "correlation_df = correlation_df[['Company', 'Correlation']]\n",
    "correlation_df.to_csv('correlation_df.csv', index=False)\n",
    "print(correlation_df)\n",
    "\n",
    "import networkx as nx   \n",
    "import matplotlib.pyplot as plt\n",
    "# Create a graph object\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "for company in company_list:\n",
    "    G.add_node(company)\n",
    "\n",
    "# Add edges to the graph\n",
    "for i in range(len(company_pairs)):\n",
    "    company1 = company_pairs[i][0]\n",
    "    company2 = company_pairs[i][1]\n",
    "    correlation = correlation_value_list[i]\n",
    "    # if abs(correlation) > 0.5:\n",
    "    #     G.add_edge(company1, company2, weight=correlation)\n",
    "    G.add_edge(company1, company2, weight=correlation)\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(12, 12))\n",
    "pos = nx.spring_layout(G)\n",
    "\n",
    "# Draw edges with weights\n",
    "edges = G.edges(data=True)\n",
    "nx.draw_networkx_edges(G, pos, edgelist=edges, width=[d['weight'] for (u, v, d) in edges])\n",
    "\n",
    "# Draw nodes and labels\n",
    "nx.draw_networkx_nodes(G, pos, node_size=500, node_color='skyblue')\n",
    "nx.draw_networkx_labels(G, pos, font_size=10, font_color='black')\n",
    "\n",
    "# Draw edge labels\n",
    "edge_labels = {(u, v): f\"{d['weight']:.2f}\" for (u, v, d) in edges}\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "nx.draw(G, pos, with_labels=True, font_size=10, node_size=500, node_color='skyblue', edge_color='black', linewidths=1, font_color='black')\n",
    "plt.title('Stock Correlation Network')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be1148e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "c=[]\n",
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "c.append(a)\n",
    "c.append(b)\n",
    "c = torch.tensor(c, dtype=torch.long).t().contiguous()\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae30ba11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a=1\n",
    "b=2\n",
    "c=3\n",
    "d=[]\n",
    "d.append(a)\n",
    "d.append(b)\n",
    "d.append(c)\n",
    "d = torch.tensor(d, dtype=torch.float)\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d7b1cdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat2 must be a matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m c\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m e\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m e\n\u001b[0;32m      6\u001b[0m e\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat2 must be a matrix"
     ]
    }
   ],
   "source": [
    "c=torch.randn(2,3)\n",
    "c\n",
    "# \n",
    "e=torch.mm(c,d)\n",
    "e\n",
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8555066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.74224809e-04  1.39280439e-02  1.30586184e-02  1.59518614e-02\n",
      "   -1.74155351e-04  1.18071600e+08]\n",
      "  [ 4.64488613e-03  5.79145656e-05 -6.18736165e-03  6.97790151e-04\n",
      "    4.64497485e-03  8.97384000e+07]\n",
      "  [ 1.13854524e-02  5.21625155e-03  1.09528795e-02  5.63693631e-03\n",
      "    1.13853089e-02  9.46400000e+07]\n",
      "  ...\n",
      "  [ 1.97719146e-02  1.54316117e-02  2.12923892e-02  1.53855948e-02\n",
      "    1.97720798e-02  1.52648800e+08]\n",
      "  [-3.24071766e-03  1.55939885e-02  6.07612464e-03  1.10663181e-02\n",
      "   -3.24076661e-03  1.55712400e+08]\n",
      "  [-1.51341015e-03  8.93288626e-04  7.75709237e-04 -6.17422528e-04\n",
      "   -1.51356018e-03  1.51128400e+08]]\n",
      "\n",
      " [[ 1.56491005e-02  1.45151741e-02  1.21334275e-02  1.33333437e-02\n",
      "    1.56487444e-02  4.70230000e+06]\n",
      "  [-5.70285542e-03  1.54236119e-02  1.99850154e-04  3.16194407e-03\n",
      "   -5.70285160e-03  3.57900000e+06]\n",
      "  [ 1.74077477e-02 -7.29493355e-03  1.07869953e-02  2.13523136e-03\n",
      "    1.74079699e-02  4.59930000e+06]\n",
      "  ...\n",
      "  [ 2.34950216e-02  7.26284073e-03  2.01995058e-02  1.83933785e-02\n",
      "    2.34947453e-02  4.47350000e+06]\n",
      "  [-2.69870889e-02  1.62656330e-02  2.30035325e-03 -7.39244785e-03\n",
      "   -2.69869917e-02  4.75430000e+06]\n",
      "  [-2.05480260e-02 -1.82328110e-02 -1.63934426e-02 -2.01422217e-02\n",
      "   -2.05479449e-02  6.66000000e+06]]\n",
      "\n",
      " [[ 2.21124794e-03  1.35739001e-02 -3.04055738e-03  8.47459357e-03\n",
      "    2.21120935e-03  5.68370000e+06]\n",
      "  [-1.69741054e-03  8.64549894e-03  9.82714334e-03  7.71732108e-03\n",
      "   -1.69718268e-03  6.24000000e+06]\n",
      "  [ 2.89036995e-03 -7.73107563e-03 -8.55701371e-03 -2.04218863e-03\n",
      "    2.89020741e-03  5.83690000e+06]\n",
      "  ...\n",
      "  [ 1.37331321e-02  1.08071596e-02  1.42282888e-02  1.27161750e-02\n",
      "    1.37330433e-02  5.36420000e+06]\n",
      "  [ 3.30435197e-04  1.48680084e-02  1.07278759e-02  1.10497070e-02\n",
      "    3.30414676e-04  6.74770000e+06]\n",
      "  [-3.63351630e-03 -1.31690535e-03 -1.95955252e-03 -3.47738042e-03\n",
      "   -3.63331137e-03  8.32570000e+06]]\n",
      "\n",
      " [[ 4.61509342e-03 -3.32244300e-03  5.77546376e-03  1.37456474e-03\n",
      "    4.61523023e-03  2.06420000e+06]\n",
      "  [ 1.18410961e-02  1.31380805e-02  1.20652683e-02  1.16347405e-02\n",
      "    1.18408409e-02  1.77700000e+06]\n",
      "  [ 8.24911307e-03  1.03871032e-02  5.48259591e-03  8.78723890e-03\n",
      "    8.24909169e-03  1.59760000e+06]\n",
      "  ...\n",
      "  [ 1.09851324e-02  1.68839286e-02  1.09168903e-02  1.62175080e-02\n",
      "    1.09850140e-02  1.78280000e+06]\n",
      "  [-1.32938761e-02  5.98215089e-03  4.55014252e-03 -2.27102262e-03\n",
      "   -1.32936866e-02  1.82080000e+06]\n",
      "  [-9.47387548e-03 -1.15291806e-02 -7.18687635e-03 -9.84316192e-03\n",
      "   -9.47405704e-03  2.00220000e+06]]\n",
      "\n",
      " [[ 1.87957009e-02  1.22262947e-02  2.30033517e-02  1.39221846e-02\n",
      "    1.87957009e-02  2.56120000e+06]\n",
      "  [ 1.20415824e-02  2.20786124e-02  1.19302821e-02  2.21722120e-02\n",
      "    1.20415824e-02  2.21140000e+06]\n",
      "  [ 1.15707619e-02  1.68746612e-02  9.99671857e-03  1.04602181e-02\n",
      "    1.15707619e-02  2.37650000e+06]\n",
      "  ...\n",
      "  [ 1.14903640e-02  3.46194886e-02  1.22509630e-02  2.92656390e-02\n",
      "    1.14903640e-02  2.41870000e+06]\n",
      "  [-1.56963804e-02  3.31303906e-03  1.93072281e-03 -4.82650781e-03\n",
      "   -1.56963804e-02  2.33080000e+06]\n",
      "  [ 1.48452251e-03 -6.13237874e-03  3.19612247e-03  4.08166146e-03\n",
      "    1.48452251e-03  2.35690000e+06]]]\n"
     ]
    }
   ],
   "source": [
    "# pkl\n",
    "import pickle\n",
    "with open('stock_data.pkl', 'rb') as f:\n",
    "    correlation_matrix = pickle.load(f)\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590f2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980, 8)\n",
      "(20, 99, 6)\n",
      "[Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20])]\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from model_first import construct_graph\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "def create_data(stock_data, correlation_matrix, window=20, batch_size=32):\n",
    "    num_stocks, num_time_steps, num_features = stock_data.shape\n",
    "\n",
    "    # \n",
    "    scaler = StandardScaler()\n",
    "     #  stock_data stock_data  (num_stocks, num_time_steps, num_features) \n",
    "    stock_data = scaler.fit_transform(stock_data.reshape(-1, num_features)).reshape(num_stocks, num_time_steps, num_features)\n",
    "   \n",
    "    \n",
    "    # \n",
    "    batch_data_list = []\n",
    "\n",
    "    # \n",
    "    for start in range(num_time_steps - window):\n",
    "\n",
    "        # 20\n",
    "        node_features = torch.tensor(stock_data[:, start:start + window, 3], dtype=torch.float32)  # \n",
    "        node_features = node_features.view(num_stocks, window)\n",
    "\n",
    "        # \n",
    "        edge_index, edge_attr = construct_graph(correlation_matrix, threshold=0.1)\n",
    "\n",
    "        # \n",
    "        y = torch.tensor(stock_data[:, start + window, 3], dtype=torch.float32)\n",
    "\n",
    "        #  Data((num_nodes, time_step=20), torch.Size([2, num_edges]), torch.Size([num_edges]), (num_nodes, num_targets=1))\n",
    "        data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "    \n",
    "        # \n",
    "        batch_data_list.append(data)\n",
    "\n",
    "    # num_stocks*batch_size\n",
    "    print(batch_data_list)\n",
    "    return batch_data_list\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "import pickle\n",
    "with open('my_data.pkl', 'rb') as f:\n",
    "    my_data = pickle.load(f)\n",
    "print(my_data.shape)\n",
    "\n",
    "#  \n",
    "stock_data = np.zeros((20, 99, 6))\n",
    "\n",
    "#  stock_data,(num_stock, num_days, num_features)\n",
    "for i, stock_code in enumerate(my_data['code'].unique()):\n",
    "    stock_data[i] = my_data[my_data['code'] == stock_code].iloc[:, 1:7].values\n",
    "\n",
    "print(stock_data.shape)\n",
    "# \n",
    "correlation_path=r\"C:\\Users\\yuqin\\firsttry\\data\\correlation_matrix.csv\"\n",
    "correlation_matrix = pd.read_csv(correlation_path)\n",
    "correlation_matrix = correlation_matrix.iloc[0:20, 1:21].values\n",
    "\n",
    "batch_data_list = create_data(stock_data, correlation_matrix, window=20, batch_size=32)\n",
    "train_data, test_data = train_test_split(batch_data_list, test_size=0.2, random_state=42)#\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True) \n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "60e74e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([640, 20])\n",
      "x shape: torch.Size([32, 20])\n",
      "x shape: torch.Size([620, 20])\n",
      "x shape: torch.Size([31, 20])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def _map_to_global(self, edge_index, batch_index):\n",
    "        # \n",
    "        num_nodes = batch_index.size(0)  # \n",
    "        # \n",
    "        global_edge_index = edge_index.clone()\n",
    "        # \n",
    "        node_offsets = torch.cumsum(torch.bincount(batch_index), dim=0)\n",
    "        node_offsets = torch.cat([torch.tensor([0], device=edge_index.device), node_offsets[:-1]])\n",
    "\n",
    "        # \n",
    "        global_edge_index[0] += node_offsets[batch_index[edge_index[0]]]\n",
    "        global_edge_index[1] += node_offsets[batch_index[edge_index[1]]]\n",
    "    \n",
    "        return global_edge_index\n",
    "for batch in train_loader:\n",
    "    x, edge_index, edge_attr, batch_index = batch.x, batch.edge_index, batch.edge_attr, batch.batch\n",
    "    print(\"x shape:\", x.shape)\n",
    "    x = global_mean_pool(x, batch_index)\n",
    "    print(\"x shape:\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5be10cb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_attr):\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x, edge_index)\n\u001b[1;32m----> 8\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mGCNLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# import model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# from model import *\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[47], line 4\u001b[0m, in \u001b[0;36mGCNLayer.__init__\u001b[1;34m(self, in_channels, out_channels)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_channels, out_channels):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m(GCNLayer, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv \u001b[38;5;241m=\u001b[39m \u001b[43mGCNConv\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:210\u001b[0m, in \u001b[0;36mGCNConv.__init__\u001b[1;34m(self, in_channels, out_channels, improved, cached, add_self_loops, normalize, bias, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_adj_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin \u001b[38;5;241m=\u001b[39m \u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mweight_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mglorot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_channels))\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch_geometric\\nn\\dense\\linear.py:103\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_channels, out_channels, bias, weight_initializer, bias_initializer)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_initializer \u001b[38;5;241m=\u001b[39m weight_initializer\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_initializer \u001b[38;5;241m=\u001b[39m bias_initializer\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43min_channels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_channels, in_channels))\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.conv = GCNConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        return self.conv(x, edge_index)\n",
    "x = GCNLayer(x, edge_index)\n",
    "# import model\n",
    "# from model import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40912a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(640,64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "343058f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (60x5 and 20x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m GCNStockPredictor(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtrainer\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m loss_values \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yuqin\\firsttry\\trainer.py:19\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, epochs, lr)\u001b[0m\n\u001b[0;32m     17\u001b[0m y\u001b[38;5;241m=\u001b[39mbatch\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[0;32m     21\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\yuqin\\firsttry\\model.py:69\u001b[0m, in \u001b[0;36mGCNStockPredictor.forward\u001b[1;34m(self, x, edge_index, edge_attr, batch_index)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_attr, batch_index):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# Step 1: Transformer\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     edge_index, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_to_global(edge_index, batch_index)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# Step 2: GCN\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\yuqin\\firsttry\\model.py:40\u001b[0m, in \u001b[0;36mStockPriceTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# x  [batch_size*num_stocks, num_features]\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#  [batch_size*num_stocks, num_features, hidden_dim][640,64]\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(x)\u001b[38;5;66;03m#[640,64]\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# [batch_size * num_stocks, hidden_dim] \u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (60x5 and 20x64)"
     ]
    }
   ],
   "source": [
    "model = GCNStockPredictor(input_dim=20, hidden_dim=64, num_heads=4, num_layers=2)\n",
    "import trainer\n",
    "loss_values = trainer.train_model(model, train_loader, epochs=50, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9d1848e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 50)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = range(0,50)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c90eb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              dt      open      high       low     close  adj close  \\\n",
      "0     2018-01-03 -0.000174  0.013928  0.013059  0.015952  -0.000174   \n",
      "1     2018-01-04  0.004645  0.000058 -0.006187  0.000698   0.004645   \n",
      "2     2018-01-05  0.011385  0.005216  0.010953  0.005637   0.011385   \n",
      "3     2018-01-08 -0.003714  0.005247  0.001369  0.005085  -0.003714   \n",
      "4     2018-01-09 -0.000115  0.001147 -0.003132 -0.002990  -0.000115   \n",
      "...          ...       ...       ...       ...       ...        ...   \n",
      "1975  2018-05-18 -0.006949 -0.001045 -0.001348 -0.003508  -0.006949   \n",
      "1976  2018-05-21  0.007609 -0.000810  0.004503  0.006055   0.007609   \n",
      "1977  2018-05-22  0.001251  0.003714  0.001763  0.000883   0.001251   \n",
      "1978  2018-05-23 -0.008724 -0.002691 -0.005766 -0.011348  -0.008724   \n",
      "1979  2018-05-24 -0.008662 -0.008499 -0.008328 -0.004869  -0.008662   \n",
      "\n",
      "         volume   code  \n",
      "0     118071600   AAPL  \n",
      "1      89738400   AAPL  \n",
      "2      94640000   AAPL  \n",
      "3      82271200   AAPL  \n",
      "4      86336000   AAPL  \n",
      "...         ...    ...  \n",
      "1975          2  BRK-A  \n",
      "1976          2  BRK-A  \n",
      "1977          2  BRK-A  \n",
      "1978          3  BRK-A  \n",
      "1979          2  BRK-A  \n",
      "\n",
      "[1980 rows x 8 columns]\n",
      "(20, 99, 6)\n",
      "(20, 99)\n"
     ]
    }
   ],
   "source": [
    "# pickle\n",
    "import pickle\n",
    "import numpy as np\n",
    "path = r\"C:\\Users\\yuqin\\firsttry\\my_data.pkl\"\n",
    "with open(path, 'rb') as f:\n",
    "    all_data = pickle.load(f)\n",
    "print(all_data)\n",
    "\n",
    "\n",
    "#  \n",
    "stock_data = np.zeros((20, 99, 6))\n",
    "\n",
    "#  stock_data\n",
    "for i, stock_code in enumerate(all_data['code'].unique()):\n",
    "    stock_data[i] = all_data[all_data['code'] == stock_code].iloc[:, 1:7].values\n",
    "print(stock_data.shape)\n",
    "\n",
    "#\n",
    "stock_data = stock_data[:,:,3]\n",
    "print(stock_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95479cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.34570737 0.47283659 0.55249954 0.61009722 0.45695348 0.\n",
      "  0.38312227 0.59880894 0.41630392 0.53720866 0.53197557 0.\n",
      "  0.3536525  0.44786552 0.35994177 0.42345182 0.4155628  0.\n",
      "  0.50295923]\n",
      " [1.         0.40229613 0.4631461  0.37880335 0.42315322 0.\n",
      "  0.30733124 0.         0.3472091  0.33578641 0.35042355 0.\n",
      "  0.33124755 0.         0.36499972 0.31049028 0.30872149 0.\n",
      "  0.44327585]\n",
      " [0.40229613 1.         0.5424515  0.47328888 0.46139523 0.39858058\n",
      "  0.45391007 0.4219725  0.4646266  0.39039319 0.38535399 0.43411242\n",
      "  0.         0.33433266 0.34421573 0.34652557 0.35206444 0.\n",
      "  0.49772766]\n",
      " [0.4631461  0.5424515  1.         0.56879953 0.64562938 0.45750113\n",
      "  0.49728997 0.48639143 0.59132908 0.55691209 0.50245404 0.38512949\n",
      "  0.44161783 0.39750941 0.52887541 0.53784392 0.54263812 0.41485842\n",
      "  0.63924216]\n",
      " [0.37880335 0.47328888 0.56879953 1.         0.51610796 0.\n",
      "  0.32916031 0.6545379  0.38259856 0.59494098 0.50323015 0.\n",
      "  0.3599567  0.47564769 0.         0.37241738 0.36808643 0.\n",
      "  0.41720607]\n",
      " [0.42315322 0.46139523 0.64562938 0.51610796 1.         0.45329495\n",
      "  0.42736645 0.36522701 0.48750622 0.48401564 0.49100961 0.38285526\n",
      "  0.5097011  0.32678872 0.4888225  0.44384241 0.44450306 0.43467955\n",
      "  0.60150504]\n",
      " [0.         0.39858058 0.45750113 0.         0.45329495 1.\n",
      "  0.59272596 0.         0.44357139 0.         0.         0.73676537\n",
      "  0.         0.         0.30857746 0.         0.         0.\n",
      "  0.38710736]\n",
      " [0.30733124 0.45391007 0.49728997 0.32916031 0.42736645 0.59272596\n",
      "  1.         0.         0.42616276 0.         0.         0.59237524\n",
      "  0.         0.         0.30289055 0.         0.         0.\n",
      "  0.37002301]\n",
      " [0.         0.4219725  0.48639143 0.6545379  0.36522701 0.\n",
      "  0.         1.         0.36088744 0.47373911 0.41450173 0.\n",
      "  0.         0.50568213 0.         0.3451527  0.34728246 0.\n",
      "  0.36993494]\n",
      " [0.3472091  0.4646266  0.59132908 0.38259856 0.48750622 0.44357139\n",
      "  0.42616276 0.36088744 1.         0.42786511 0.4121022  0.39415317\n",
      "  0.39711068 0.34726721 0.53638504 0.54337182 0.55310869 0.42282811\n",
      "  0.57374676]\n",
      " [0.33578641 0.39039319 0.55691209 0.59494098 0.48401564 0.\n",
      "  0.         0.47373911 0.42786511 1.         0.63119037 0.\n",
      "  0.42415911 0.45763709 0.38778576 0.52989207 0.53495177 0.37931822\n",
      "  0.50979264]\n",
      " [0.35042355 0.38535399 0.50245404 0.50323015 0.49100961 0.\n",
      "  0.         0.41450173 0.4121022  0.63119037 1.         0.\n",
      "  0.44616867 0.41791623 0.40987432 0.44139767 0.4455359  0.39170777\n",
      "  0.53684823]\n",
      " [0.         0.43411242 0.38512949 0.         0.38285526 0.73676537\n",
      "  0.59237524 0.         0.39415317 0.         0.         1.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.32778517]\n",
      " [0.33124755 0.         0.44161783 0.3599567  0.5097011  0.\n",
      "  0.         0.         0.39711068 0.42415911 0.44616867 0.\n",
      "  1.         0.31509042 0.57220543 0.46880404 0.46425409 0.57866581\n",
      "  0.57026473]\n",
      " [0.         0.33433266 0.39750941 0.47564769 0.32678872 0.\n",
      "  0.         0.50568213 0.34726721 0.45763709 0.41791623 0.\n",
      "  0.31509042 1.         0.30258921 0.39454939 0.40907634 0.\n",
      "  0.40678852]\n",
      " [0.36499972 0.34421573 0.52887541 0.         0.4888225  0.30857746\n",
      "  0.30289055 0.         0.53638504 0.38778576 0.40987432 0.\n",
      "  0.57220543 0.30258921 1.         0.57025269 0.56899016 0.58688599\n",
      "  0.72701315]\n",
      " [0.31049028 0.34652557 0.53784392 0.37241738 0.44384241 0.\n",
      "  0.         0.3451527  0.54337182 0.52989207 0.44139767 0.\n",
      "  0.46880404 0.39454939 0.57025269 1.         0.96683854 0.64469506\n",
      "  0.58216809]\n",
      " [0.30872149 0.35206444 0.54263812 0.36808643 0.44450306 0.\n",
      "  0.         0.34728246 0.55310869 0.53495177 0.4455359  0.\n",
      "  0.46425409 0.40907634 0.56899016 0.96683854 1.         0.6353208\n",
      "  0.583235  ]\n",
      " [0.         0.         0.41485842 0.         0.43467955 0.\n",
      "  0.         0.         0.42282811 0.37931822 0.39170777 0.\n",
      "  0.57866581 0.         0.58688599 0.64469506 0.6353208  1.\n",
      "  0.55662442]\n",
      " [0.44327585 0.49772766 0.63924216 0.41720607 0.60150504 0.38710736\n",
      "  0.37002301 0.36993494 0.57374676 0.50979264 0.53684823 0.32778517\n",
      "  0.57026473 0.40678852 0.72701315 0.58216809 0.583235   0.55662442\n",
      "  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from data.feature_adjacent_matrix import fadj\n",
    "# 0.30\n",
    "fadj[fadj<0.3] = 0\n",
    "print(fadj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "485c6275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6369,  0.4135, -0.2983, -0.8699],\n",
      "        [ 1.8241, -0.4960, -0.7140, -0.2375],\n",
      "        [ 0.5532,  1.4378,  1.2707, -1.6193],\n",
      "        [-0.7798,  0.7177, -0.8455,  0.4825]])\n",
      "tensor([[0.0000, 0.4135, 0.0000, 0.0000],\n",
      "        [1.8241, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5532, 1.4378, 1.2707, 0.0000],\n",
      "        [0.0000, 0.7177, 0.0000, 0.4825]])\n",
      "tensor([[1.0000, 0.4135, 0.0000, 0.0000],\n",
      "        [1.8241, 1.0000, 0.0000, 0.0000],\n",
      "        [0.5532, 1.4378, 1.0000, 0.0000],\n",
      "        [0.0000, 0.7177, 0.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(4, 4)\n",
    "print(x)\n",
    "x[x<0.2] = 0\n",
    "print(x)\n",
    "# 1\n",
    "x.fill_diagonal_(1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0caa89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 1 1 8 8 6 1 3 7 3 6 7 1 2 6 4 3 2 4 8] 4.5\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "file_path =r\"C:\\Users\\yuqin\\firsttry\\data\\correlation_matrix.csv\" \n",
    "import pandas as pd\n",
    "correlation_matrix = pd.read_csv(file_path)\n",
    "correlation_matrix = correlation_matrix.iloc[0:20, 1:21].values\n",
    "correlation_matrix[abs(correlation_matrix)<0.3] = 0\n",
    "non_zero_count = (correlation_matrix != 0).sum(axis=1)-1\n",
    "non_zero_mean = non_zero_count.sum()/20\n",
    "print(non_zero_count, non_zero_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "829835f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([640, 20])\n",
      "edge_index shape: torch.Size([2, 9920])\n",
      "edge_attr shape: torch.Size([9920])\n"
     ]
    }
   ],
   "source": [
    "# edge_index, edge_attr\n",
    "import torch    \n",
    "from main import train_loader\n",
    "for batch in train_loader:\n",
    "    x, edge_index, edge_attr, batch_index = batch.x, batch.edge_index, batch.edge_attr, batch.batch\n",
    "    print(x.shape)\n",
    "    print(\"edge_index shape:\", edge_index.shape)\n",
    "    print(\"edge_attr shape:\", edge_attr.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd48f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "support = torch.mm(input, self.weight)\n",
    "output = torch.spmm(adj, support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ee61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x1=torch.randn(2,3)\n",
    "x2=torch.randn(3,4)\n",
    "x3=torch.mm(x1,x2)\n",
    "print(x3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a1751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.7040075   0.28613687 -0.53040224  0.02279595  0.4063969\n",
      "  -0.782793   -0.2301002  -0.27623415 -0.6315781 ]\n",
      " [ 0.7040075   1.          0.42137244 -0.19314873 -0.27792168  0.8479348\n",
      "  -0.6741278   0.1529089  -0.20142862 -0.8085135 ]\n",
      " [ 0.28613687  0.42137244  1.0000001  -0.14398791  0.62795174 -0.05037412\n",
      "  -0.81275594 -0.03430042 -0.5579583  -0.18500037]\n",
      " [-0.53040224 -0.19314873 -0.14398791  1.         -0.37615955 -0.00227043\n",
      "   0.4423832  -0.01338059 -0.43322942  0.32943538]\n",
      " [ 0.02279595 -0.27792168  0.62795174 -0.37615955  1.0000001  -0.6730782\n",
      "  -0.41525072 -0.4422981  -0.32169095  0.45272413]\n",
      " [ 0.4063969   0.8479348  -0.05037412 -0.00227043 -0.6730782   1.0000001\n",
      "  -0.18405049  0.28268802  0.12902696 -0.7198305 ]\n",
      " [-0.782793   -0.6741278  -0.81275594  0.4423832  -0.41525072 -0.18405049\n",
      "   0.99999994  0.09099747  0.48213065  0.53532284]\n",
      " [-0.2301002   0.1529089  -0.03430042 -0.01338059 -0.4422981   0.28268802\n",
      "   0.09099747  1.          0.5582822  -0.5782256 ]\n",
      " [-0.27623415 -0.20142862 -0.5579583  -0.43322942 -0.32169095  0.12902696\n",
      "   0.48213065  0.5582822   0.99999994 -0.16929874]\n",
      " [-0.6315781  -0.8085135  -0.18500037  0.32943538  0.45272413 -0.7198305\n",
      "   0.53532284 -0.5782256  -0.16929874  0.9999999 ]]\n",
      "Sparse tensor:\n",
      "tensor(indices=tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                        1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "                        3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5,\n",
      "                        5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,\n",
      "                        7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9,\n",
      "                        9, 9, 9, 9, 9],\n",
      "                       [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8,\n",
      "                        9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "                        8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6,\n",
      "                        7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,\n",
      "                        6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4,\n",
      "                        5, 6, 7, 8, 9]]),\n",
      "       values=tensor([ 1.0000,  0.7040,  0.2861, -0.5304,  0.0228,  0.4064,\n",
      "                      -0.7828, -0.2301, -0.2762, -0.6316,  0.7040,  1.0000,\n",
      "                       0.4214, -0.1931, -0.2779,  0.8479, -0.6741,  0.1529,\n",
      "                      -0.2014, -0.8085,  0.2861,  0.4214,  1.0000, -0.1440,\n",
      "                       0.6280, -0.0504, -0.8128, -0.0343, -0.5580, -0.1850,\n",
      "                      -0.5304, -0.1931, -0.1440,  1.0000, -0.3762, -0.0023,\n",
      "                       0.4424, -0.0134, -0.4332,  0.3294,  0.0228, -0.2779,\n",
      "                       0.6280, -0.3762,  1.0000, -0.6731, -0.4153, -0.4423,\n",
      "                      -0.3217,  0.4527,  0.4064,  0.8479, -0.0504, -0.0023,\n",
      "                      -0.6731,  1.0000, -0.1841,  0.2827,  0.1290, -0.7198,\n",
      "                      -0.7828, -0.6741, -0.8128,  0.4424, -0.4153, -0.1841,\n",
      "                       1.0000,  0.0910,  0.4821,  0.5353, -0.2301,  0.1529,\n",
      "                      -0.0343, -0.0134, -0.4423,  0.2827,  0.0910,  1.0000,\n",
      "                       0.5583, -0.5782, -0.2762, -0.2014, -0.5580, -0.4332,\n",
      "                      -0.3217,  0.1290,  0.4821,  0.5583,  1.0000, -0.1693,\n",
      "                      -0.6316, -0.8085, -0.1850,  0.3294,  0.4527, -0.7198,\n",
      "                       0.5353, -0.5782, -0.1693,  1.0000]),\n",
      "       size=(10, 10), nnz=100, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "# adj\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "x1=torch.randn(10,5)\n",
    "matrix = cosine_similarity(x1)\n",
    "print(matrix)\n",
    "import numpy as np\n",
    "indices = np.array(np.nonzero(matrix))  # \n",
    "values = matrix[indices[0], indices[1]]  # \n",
    "\n",
    "#  indices  torch.Tensor\n",
    "indices = torch.LongTensor(indices)\n",
    "\n",
    "#  values  torch.Tensor\n",
    "values = torch.FloatTensor(values)\n",
    "\n",
    "# \n",
    "shape = matrix.shape  # \n",
    "sparse_tensor = torch.sparse_coo_tensor(indices, values, shape)\n",
    "\n",
    "# \n",
    "print(\"Sparse tensor:\")\n",
    "print(sparse_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj\n",
    "tensor = torch.from_numpy(matrix)\n",
    "output = torch.spmm(tensor, support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1a92685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20)\n",
      "sadj  numpy.ndarray\n",
      "sadj  numpy.ndarray\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "correlation_path=r\"C:\\Users\\yuqin\\firsttry\\data\\correlation_matrix.csv\"\n",
    "correlation_matrix = pd.read_csv(correlation_path)\n",
    "sadj = correlation_matrix.iloc[0:20, 1:21].values\n",
    "sadj[sadj < 0.3] = 0  # 0.3\n",
    "print(sadj.shape)\n",
    "#  numpy.ndarray \n",
    "if isinstance(sadj, np.ndarray):\n",
    "    print(\"sadj  numpy.ndarray\")\n",
    "else:\n",
    "    print(\"sadj  numpy.ndarray\")\n",
    "sadj = torch.tensor(sadj, dtype=torch.float32)\n",
    "if isinstance(sadj, np.ndarray):\n",
    "    print(\"sadj  numpy.ndarray\")\n",
    "else:\n",
    "    print(\"sadj  numpy.ndarray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20758c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8144, -2.2193, -0.4141, -0.8200, -0.4098],\n",
      "        [-1.5581,  1.1052, -1.4366,  1.6742,  0.7849],\n",
      "        [-0.7761, -0.7545, -0.8297,  0.4517,  0.6463],\n",
      "        [ 0.3189,  0.0555,  1.2401, -0.5318,  2.0426],\n",
      "        [ 0.6017,  0.5958,  0.3841, -0.8141,  0.4347]])\n",
      "tensor([[0, 4],\n",
      "        [3, 1],\n",
      "        [4, 3],\n",
      "        [4, 2],\n",
      "        [0, 1]])\n",
      "tensor([[ 1.8144,  0.0000,  0.0000,  0.0000, -0.4098],\n",
      "        [ 0.0000,  1.1052,  0.0000,  1.6742,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.4517,  0.6463],\n",
      "        [ 0.0000,  0.0000,  1.2401,  0.0000,  2.0426],\n",
      "        [ 0.6017,  0.5958,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(5,5)\n",
    "print(x)\n",
    "# 50\n",
    "_, indices = x.topk(2, dim=1)\n",
    "print(indices)\n",
    "for i in range(x.size(0)):\n",
    "    x[i][x[i] < x[i, indices[i][-1]]] = 0\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65b7db52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[640, 20], edge_index=[2, 9920], edge_attr=[9920], y=[640], batch=[640], ptr=[33])\n",
      "DataBatch(x=[620, 20], edge_index=[2, 9610], edge_attr=[9610], y=[620], batch=[620], ptr=[32])\n"
     ]
    }
   ],
   "source": [
    "from main import train_loader\n",
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "\n",
    "            # x, edge_index, batch_index, fadj, sadj = batch.x, batch.edge_index, batch.batch, batch.fadj, batch.sadj\n",
    "            # print(\"x shape:\", x.shape, \"edge_index shape:\", edge_index.shape,  \"fadj shape:\", fadj.shape, \"sadj shape:\", sadj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5dc86d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20])]\n"
     ]
    }
   ],
   "source": [
    "from main import train_loader, batch_data_list\n",
    "\n",
    "# for batch in train_loader:\n",
    "#     x, edge_index, edge_attr, batch_index, fadj, sadj = batch.x, batch.edge_index, batch.edge_attr, batch.batch, batch.fadj, batch.sadj\n",
    "#     print(\"x shape:\", x.shape, \"edge_index shape:\", edge_index.shape,  \"fadj shape:\", fadj.shape, \"sadj shape:\", sadj.shape)\n",
    "#     break\n",
    "print(batch_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd2037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    " \n",
    "# \n",
    "np.random.seed(0)\n",
    " \n",
    " \n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        sequence, label = self.sequences[index]\n",
    "        return torch.Tensor(sequence), torch.Tensor(label)\n",
    " \n",
    " \n",
    "def calculate_mae(y_true, y_pred):\n",
    "    # \n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    return mae\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "true_data = pd.read_csv('ETTh1.csv')  # ,\n",
    " \n",
    " \n",
    "target = 'OT'  # \n",
    "test_size = 0.15  # \n",
    "train_size = 0.85  # \n",
    "pre_len = 4  # \n",
    "train_window = 32  # \n",
    " \n",
    "# , pd.series\n",
    "true_data = np.array(true_data[target])\n",
    " \n",
    "# \n",
    "scaler_train = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_test = MinMaxScaler(feature_range=(0, 1))\n",
    " \n",
    "# \n",
    "train_data = true_data[:int(train_size * len(true_data))]\n",
    "test_data = true_data[-int(test_size * len(true_data)):]\n",
    "print(\":\", len(train_data))\n",
    "print(\":\", len(test_data))\n",
    " \n",
    "# \n",
    "train_data_normalized = scaler_train.fit_transform(train_data.reshape(-1, 1))\n",
    "test_data_normalized = scaler_test.fit_transform(test_data.reshape(-1, 1))\n",
    " \n",
    "# Tensor\n",
    "train_data_normalized = torch.FloatTensor(train_data_normalized)\n",
    "test_data_normalized = torch.FloatTensor(test_data_normalized)\n",
    " \n",
    " \n",
    "def create_inout_sequences(input_data, tw, pre_len):\n",
    "    # \n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L - tw):\n",
    "        train_seq = input_data[i:i + tw]\n",
    "        if (i + tw + 4) > len(input_data):\n",
    "            break\n",
    "        train_label = input_data[i + tw:i + tw + pre_len]\n",
    "        inout_seq.append((train_seq, train_label))\n",
    "    return inout_seq\n",
    " \n",
    " \n",
    "# \n",
    "train_inout_seq = create_inout_sequences(train_data_normalized, train_window, pre_len)\n",
    "test_inout_seq = create_inout_sequences(test_data_normalized, train_window, pre_len)\n",
    " \n",
    "# \n",
    "train_dataset = TimeSeriesDataset(train_inout_seq)\n",
    "test_dataset = TimeSeriesDataset(test_inout_seq)\n",
    " \n",
    "#  DataLoader\n",
    "batch_size = 32  # \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    " \n",
    " \n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=32, num_layers=1, output_dim=1, pre_len= 4):\n",
    "        super(GRU, self).__init__()\n",
    "        self.pre_len = pre_len\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        #  LSTM  GRU\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim,num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    def forward(self, x):\n",
    "        h0_gru = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    " \n",
    "        out, _ = self.gru(x, h0_gru)\n",
    " \n",
    "        out = self.dropout(out)\n",
    " \n",
    "        #  pre_len \n",
    "        out = out[:, -self.pre_len:, :]\n",
    " \n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    " \n",
    " \n",
    "lstm_model = GRU(input_dim=1, output_dim=1, num_layers=2, hidden_dim=train_window, pre_len=pre_len)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.005)\n",
    "epochs = 20\n",
    "Train = True  # \n",
    " \n",
    "if Train:\n",
    "    losss = []\n",
    "    lstm_model.train()  # \n",
    "    for i in range(epochs):\n",
    "        start_time = time.time()  # \n",
    "        for seq, labels in train_loader:\n",
    "            lstm_model.train()\n",
    "            optimizer.zero_grad()\n",
    " \n",
    "            y_pred = lstm_model(seq)\n",
    " \n",
    "            single_loss = loss_function(y_pred, labels)\n",
    " \n",
    "            single_loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "        losss.append(single_loss.detach().numpy())\n",
    "    torch.save(lstm_model.state_dict(), 'save_model.pth')\n",
    "    print(f\",:{(time.time() - start_time) / 60:.4f} min\")\n",
    " \n",
    " \n",
    "else:\n",
    "    # \n",
    "    lstm_model.load_state_dict(torch.load('save_model.pth'))\n",
    "    lstm_model.eval()  # \n",
    "    results = []\n",
    "    reals = []\n",
    "    losss = []\n",
    " \n",
    "    for seq, labels in test_loader:\n",
    "        pred = lstm_model(seq)\n",
    "        mae = calculate_mae(pred.detach().numpy(), np.array(labels))  # MAE(  - )\n",
    "        losss.append(mae)\n",
    "        for j in range(batch_size):\n",
    "            for i in range(pre_len):\n",
    "                reals.append(labels[j][i][0].detach().numpy())\n",
    "                results.append(pred[j][i][0].detach().numpy())\n",
    " \n",
    "    reals = scaler_test.inverse_transform(np.array(reals).reshape(1, -1))[0]\n",
    "    results = scaler_test.inverse_transform(np.array(results).reshape(1, -1))[0]\n",
    "    print(\"\", results)\n",
    "    print(\"MAE:\", losss)\n",
    " \n",
    "    plt.figure()\n",
    "    plt.style.use('ggplot')\n",
    " \n",
    "    # \n",
    "    plt.plot(reals, label='real', color='blue')  # \n",
    "    plt.plot(results, label='forecast', color='red', linestyle='--')  # \n",
    " \n",
    "    # \n",
    "    plt.grid(True)\n",
    "    plt.title('real vs forecast')\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('value')\n",
    "    plt.legend()\n",
    "    plt.savefig('testresults.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69d5e450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([[ 0.5534, -0.3601, -0.6340],\n",
      "        [ 0.1635,  1.5712,  0.8667],\n",
      "        [ 1.1764, -0.1071, -0.4689]]), 1, tensor([[ 1.5534, -0.3601, -0.6340],\n",
      "        [ 0.1635,  2.5712,  0.8667],\n",
      "        [ 1.1764, -0.1071,  0.5311]])), (tensor([[ 0.8329,  0.1977, -1.0800],\n",
      "        [-0.8097,  0.7092,  1.4769],\n",
      "        [ 0.8609, -0.3399, -1.0729]]), 2, tensor([[ 1.8329,  0.1977, -1.0800],\n",
      "        [-0.8097,  1.7092,  1.4769],\n",
      "        [ 0.8609, -0.3399, -0.0729]])), (tensor([[-0.1230, -0.6563, -0.6860],\n",
      "        [-1.3283, -1.0717,  1.6726],\n",
      "        [-0.0964,  0.0634, -1.2715]]), 3, tensor([[ 0.8770, -0.6563, -0.6860],\n",
      "        [-1.3283, -0.0717,  1.6726],\n",
      "        [-0.0964,  0.0634, -0.2715]])), (tensor([[-0.9171, -0.0213,  1.6839],\n",
      "        [ 1.3951, -1.6313,  0.9454],\n",
      "        [-0.9708,  1.0789,  0.7826]]), 4, tensor([[ 0.0829, -0.0213,  1.6839],\n",
      "        [ 1.3951, -0.6313,  0.9454],\n",
      "        [-0.9708,  1.0789,  1.7826]])), (tensor([[-1.0664,  0.1757, -0.7298],\n",
      "        [-1.2734,  0.7878,  1.1489],\n",
      "        [ 0.5370,  0.5216, -0.5192]]), 5, tensor([[-0.0664,  0.1757, -0.7298],\n",
      "        [-1.2734,  1.7878,  1.1489],\n",
      "        [ 0.5370,  0.5216,  0.4808]]))]\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "x1 = torch.randn(3,3)\n",
    "x2 = torch.randn(3,3)\n",
    "x3 = torch.randn(3,3)\n",
    "x4 = torch.randn(3,3)\n",
    "x5 = torch.randn(3,3)\n",
    "y1 = 1\n",
    "y2 = 2\n",
    "y3 = 3\n",
    "y4 = 4\n",
    "y5 = 5\n",
    "z1 = sadj = x1 + torch.eye(x1.size(0), dtype=torch.float32)\n",
    "z2 = sadj = x2 + torch.eye(x2.size(0), dtype=torch.float32)\n",
    "z3 = sadj = x3 + torch.eye(x3.size(0), dtype=torch.float32)\n",
    "z4 = sadj = x4 + torch.eye(x4.size(0), dtype=torch.float32)\n",
    "z5 = sadj = x5 + torch.eye(x5.size(0), dtype=torch.float32)\n",
    "list = []\n",
    "list.append((x1,y1,z1))\n",
    "list.append((x2,y2,z2))\n",
    "list.append((x3,y3,z3))\n",
    "list.append((x4,y4,z4))\n",
    "list.append((x5,y5,z5))\n",
    "print(list)\n",
    "train_data, test_data = train_test_split(list, test_size=0.2, random_state=42)\n",
    "for i in train_data:\n",
    "    x = i[2]\n",
    "    y = i[1]\n",
    "    print(x.dtype)\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57732202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.randn(3,3)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2e1b59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m MyNeuralNetwork()\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# GPU\u001b[39;00m\n\u001b[1;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MyNeuralNetwork().to(device)  # GPU\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# \n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c1fc5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch \n",
    "# Specify the directory\n",
    "directory = 'CMIN/CMIN-US/price/raw/'\n",
    "# List all files in the directory\n",
    "filenames = os.listdir(directory)\n",
    "company_list = []\n",
    "for filename in filenames:\n",
    "    filename = filename[:-4]\n",
    "    company_list.append(filename)\n",
    "\n",
    "n_company =len(company_list)\n",
    "n_company\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db9022ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n"
     ]
    }
   ],
   "source": [
    "print('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b30eb8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEM.txt', 'AAPL.txt', 'NFLX.txt', 'ABBV.txt', 'NGG.txt', 'ABT.txt', 'NKE.txt', 'ACN.txt', 'NVO.txt', 'ADBE.txt', 'NVDA.txt', 'ADP.txt', 'NVS.txt', 'AEP.txt', 'O.txt', 'AMT.txt', 'RIO.txt', 'AMZN.txt', 'RTX.txt', 'APD.txt', 'SBAC.txt', 'ASML.txt', 'SBUX.txt', 'AVGO.txt', 'SCHW.txt', 'AWK.txt', 'SHW.txt', 'BA.txt', 'SNP.txt', 'BABA.txt', 'SO.txt', 'BAC.txt', 'SPG-PJ.txt', 'BBL.txt', 'SRE.txt', 'BHP.txt', 'T.txt', 'BP.txt', 'TGT.txt', 'BRK-A.txt', 'TM.txt', 'C-PJ.txt', 'TMO.txt', 'CAT.txt', 'TMUS.txt', 'CCI.txt', 'TSLA.txt', 'CHTR.txt', 'TSM.txt', 'CMCSA.txt', 'TTE.txt', 'COP.txt', 'UL.txt', 'COST.txt', 'UNH.txt', 'CSCO.txt', 'UPS.txt', 'CTA-PB.txt', 'Unp.txt', 'CVX.txt', 'V.txt', 'D.txt', 'VALE.txt', 'DE.txt', 'VZ.txt', 'DEO.txt', 'WELL.txt', 'DHR.txt', 'WFC-PL.txt', 'DIS.txt', 'WMT.txt', 'DLR.txt', 'XEL.txt', 'DUK.txt', 'XOM.txt', 'ECL.txt', 'snap.txt', 'EL.txt', 'ENB.txt', 'EQIX.txt', 'EQNR.txt', 'EXC.txt', 'FB.txt', 'FCX.txt', 'GE.txt', 'GOOG.txt', 'HD.txt', 'HON.txt', 'JD.txt', 'JNJ.txt', 'JPM.txt', 'KO.txt', 'LLY.txt', 'LOW.txt', 'MA.txt', 'MCD.txt', 'MMM.txt', 'MS.txt', 'MSFT.txt', 'NEE.txt', 'ORCL.txt', 'PEP.txt', 'PFE.txt', 'PG.txt', 'PLD.txt', 'PM.txt', 'PSA.txt', 'PTR.txt', 'PYPL.txt', 'RDS-B.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "##  \n",
    "folder_path = '/root/firsttry/CMIN/CMIN-US/price/processed/'\n",
    "\n",
    "## \n",
    "file_list = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea46de3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1002, 6)\n",
      "0 NEM\n",
      "1 AAPL\n",
      "2 NFLX\n",
      "3 ABBV\n",
      "4 NGG\n",
      "5 ABT\n",
      "6 NKE\n",
      "7 ACN\n",
      "8 NVO\n",
      "9 ADBE\n",
      "10 NVDA\n",
      "11 ADP\n",
      "12 NVS\n",
      "13 AEP\n",
      "14 O\n",
      "15 AMT\n",
      "16 RIO\n",
      "17 AMZN\n",
      "18 RTX\n",
      "19 APD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from model import *\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# \n",
    "n_company = 20\n",
    "num_days = 1002  # \n",
    "num_features = 6  # 6\n",
    "\n",
    "##  \n",
    "folder_path = '/root/firsttry/CMIN/CMIN-US/price/processed/'\n",
    "\n",
    "## \n",
    "file_list = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "\n",
    "\n",
    "## DataFrame\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "##\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    df = pd.read_csv(file_path, sep='\\t', header=None, names=['dt', 'open', 'high', 'low', 'close', 'adj close', 'volume'])  # \n",
    "    df['code'] = file_name[0:-4]  # DataFrame\n",
    "    all_data = pd.concat([all_data, df], ignore_index=True)  # \n",
    "# all_data = all_data.to(device)\n",
    "\n",
    "# DataFramepkl (num_stock*num_features, index+file_name+num_features+)\n",
    "output_path = 'my_data.pkl'\n",
    "all_data.to_pickle(output_path)\n",
    "\n",
    "#  \n",
    "stock_data = np.zeros((n_company, num_days, num_features))\n",
    "print(stock_data.shape)\n",
    "#  stock_data\n",
    "for i, stock_code in enumerate(all_data['code'].unique()):\n",
    "    print(i,stock_code)\n",
    "    stock_data[i] = all_data[all_data['code'] == stock_code].iloc[:, 1:7].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f85325a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3636, 0.0000, 0.0000, 0.0636, 0.0636, 0.0636, 0.0000, 0.0636, 0.0636,\n",
      "         0.0000, 0.0636, 0.1273, 0.0000, 0.0000, 0.0636, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0636],\n",
      "        [0.0000, 0.8163, 0.1837, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.1837, 0.8163, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0700, 0.0000, 0.0000, 0.4000, 0.0600, 0.1100, 0.0000, 0.0700, 0.0800,\n",
      "         0.0000, 0.0700, 0.0700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0700],\n",
      "        [0.0714, 0.0000, 0.0000, 0.0612, 0.4082, 0.0714, 0.0000, 0.0714, 0.0918,\n",
      "         0.0000, 0.0714, 0.0918, 0.0000, 0.0000, 0.0612, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0769, 0.0000, 0.0000, 0.1209, 0.0769, 0.4396, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0769, 0.0000, 0.0000, 0.0000, 0.1319, 0.0000, 0.0000,\n",
      "         0.0000, 0.0769],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7547, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.2453, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1148, 0.0000, 0.0000, 0.1148, 0.1148, 0.0000, 0.0000, 0.6557, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0707, 0.0000, 0.0000, 0.0808, 0.0909, 0.0000, 0.0000, 0.0000, 0.4040,\n",
      "         0.0000, 0.0707, 0.0707, 0.0000, 0.0000, 0.1414, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0707],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.6349, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1111, 0.0000,\n",
      "         0.1429, 0.1111],\n",
      "        [0.0814, 0.0000, 0.0000, 0.0814, 0.0814, 0.0000, 0.0000, 0.0000, 0.0814,\n",
      "         0.0000, 0.4651, 0.1279, 0.0000, 0.0000, 0.0814, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1373, 0.0000, 0.0000, 0.0686, 0.0882, 0.0686, 0.0000, 0.0000, 0.0686,\n",
      "         0.0000, 0.1078, 0.3922, 0.0000, 0.0000, 0.0686, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2453, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.7547, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.7143, 0.0000, 0.1607, 0.0000, 0.0000,\n",
      "         0.0000, 0.1250],\n",
      "        [0.0864, 0.0000, 0.0000, 0.0000, 0.0741, 0.0000, 0.0000, 0.0000, 0.1728,\n",
      "         0.0000, 0.0864, 0.0864, 0.0000, 0.0000, 0.4938, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1538, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.1154, 0.0000, 0.5128, 0.0000, 0.0000,\n",
      "         0.0897, 0.1282],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0877, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5013, 0.2481,\n",
      "         0.1629, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2964, 0.5988,\n",
      "         0.1048, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1184, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0921, 0.1711, 0.0921,\n",
      "         0.5263, 0.0000],\n",
      "        [0.0761, 0.0000, 0.0000, 0.0761, 0.0000, 0.0761, 0.0000, 0.0000, 0.0761,\n",
      "         0.0761, 0.0000, 0.0000, 0.0000, 0.0761, 0.0000, 0.1087, 0.0000, 0.0000,\n",
      "         0.0000, 0.4348]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "\n",
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize  matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(axis = 1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = np.diag(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "# \n",
    "n_company = 20\n",
    "correlation_path=\"/root/firsttry/data/topology_correlation_matrix.csv\"\n",
    "correlation_matrix = pd.read_csv(correlation_path)\n",
    "sadj = correlation_matrix.iloc[0:n_company, 1:(n_company+1)].values\n",
    "sadj[sadj < 0.3] = 0  # 0.3\n",
    "\n",
    "\"\"\"\n",
    "sadjtensor\n",
    "\"\"\"\n",
    "sadj = torch.tensor(sadj, dtype=torch.float32) \n",
    "sadj = sadj + sadj.T.mul(sadj.T > sadj) - sadj.mul(sadj.T > sadj)\n",
    "sadj = normalize(sadj + torch.eye(sadj.size(0), dtype=torch.float32))\n",
    "sadj = torch.from_numpy(sadj)\n",
    "print(sadj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3533db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x1 = torch.randn(3,4).to(\"cuda\")\n",
    "x1 = x1.cpu()\n",
    "print(x1.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4ed5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/100, Loss: 1.0155485020558925\n",
      "Epoch 2/100, Loss: 1.0111863929896978\n",
      "Epoch 3/100, Loss: 1.0109945485925977\n",
      "Epoch 4/100, Loss: 1.0108348470584603\n",
      "Epoch 5/100, Loss: 1.0107020746892805\n",
      "Epoch 6/100, Loss: 1.0108118383652844\n",
      "Epoch 7/100, Loss: 1.0106787442069525\n",
      "Epoch 8/100, Loss: 1.0105292524169585\n",
      "Epoch 9/100, Loss: 1.011040996000835\n",
      "Epoch 10/100, Loss: 1.0106576097808826\n",
      "Epoch 11/100, Loss: 1.0110725506713056\n",
      "Epoch 12/100, Loss: 1.0109955331512317\n",
      "Epoch 13/100, Loss: 1.0112647930338126\n",
      "Epoch 14/100, Loss: 1.0112455816405594\n",
      "Epoch 15/100, Loss: 1.0107349956633558\n",
      "Epoch 16/100, Loss: 1.0109471541348916\n",
      "Epoch 17/100, Loss: 1.0109370497001964\n",
      "Epoch 18/100, Loss: 1.0108238108788326\n",
      "Epoch 19/100, Loss: 1.0108198981945682\n",
      "Epoch 20/100, Loss: 1.0109198952651328\n",
      "Epoch 21/100, Loss: 1.0108005811406928\n",
      "Epoch 22/100, Loss: 1.0110028523406025\n",
      "Epoch 23/100, Loss: 1.0111469870255252\n",
      "Epoch 24/100, Loss: 1.0112166470830228\n",
      "Epoch 25/100, Loss: 1.0108478898550295\n",
      "Epoch 26/100, Loss: 1.0106879539977593\n",
      "Epoch 27/100, Loss: 1.0107764334198397\n",
      "Epoch 28/100, Loss: 1.0112066860221753\n",
      "Epoch 29/100, Loss: 1.0112237920521931\n",
      "Epoch 30/100, Loss: 1.0112054213691668\n",
      "Epoch 31/100, Loss: 1.011201669365927\n",
      "Epoch 32/100, Loss: 1.0107601761343372\n",
      "Epoch 33/100, Loss: 1.0106601885834317\n",
      "Epoch 34/100, Loss: 1.0109459441511115\n",
      "Epoch 35/100, Loss: 1.0110939736958522\n",
      "Epoch 36/100, Loss: 1.010916906049487\n",
      "Epoch 37/100, Loss: 1.0108812128282656\n",
      "Epoch 38/100, Loss: 1.0108753553811152\n",
      "Epoch 39/100, Loss: 1.010862812774766\n",
      "Epoch 40/100, Loss: 1.0107423221324658\n",
      "Epoch 41/100, Loss: 1.0110269607252376\n",
      "Epoch 42/100, Loss: 1.011099839096616\n",
      "Epoch 43/100, Loss: 1.011240304550927\n",
      "Epoch 44/100, Loss: 1.0112936298131563\n",
      "Epoch 45/100, Loss: 1.0107495417877748\n",
      "Epoch 46/100, Loss: 1.0108163789816342\n",
      "Epoch 47/100, Loss: 1.0108390691648623\n",
      "Epoch 48/100, Loss: 1.0108602031828111\n",
      "Epoch 49/100, Loss: 1.011093252531852\n",
      "Epoch 50/100, Loss: 1.0111326641527711\n",
      "Epoch 51/100, Loss: 1.0108716927563688\n",
      "Epoch 52/100, Loss: 1.0110933261597232\n",
      "Epoch 53/100, Loss: 1.0109621427668507\n",
      "Epoch 54/100, Loss: 1.0113296009552706\n",
      "Epoch 55/100, Loss: 1.0108777127021058\n",
      "Epoch 56/100, Loss: 1.01073261043828\n",
      "Epoch 57/100, Loss: 1.0107802331352689\n",
      "Epoch 58/100, Loss: 1.0107142859346168\n",
      "Epoch 59/100, Loss: 1.0109772768749552\n",
      "Epoch 60/100, Loss: 1.0109619684469928\n",
      "Epoch 61/100, Loss: 1.0108852764176335\n",
      "Epoch 62/100, Loss: 1.0107962427340496\n",
      "Epoch 63/100, Loss: 1.0111674331982803\n",
      "Epoch 64/100, Loss: 1.0113140882200495\n",
      "Epoch 65/100, Loss: 1.0107864872570251\n",
      "Epoch 66/100, Loss: 1.0110895707396566\n",
      "Epoch 67/100, Loss: 1.010908398829448\n",
      "Epoch 68/100, Loss: 1.0110555471460911\n",
      "Epoch 69/100, Loss: 1.0106586441777314\n",
      "Epoch 70/100, Loss: 1.010857566887406\n",
      "Epoch 71/100, Loss: 1.0109789326597172\n",
      "Epoch 72/100, Loss: 1.0108686397884301\n",
      "Epoch 73/100, Loss: 1.010904851617517\n",
      "Epoch 74/100, Loss: 1.0110519125203419\n",
      "Epoch 75/100, Loss: 1.0109573285196238\n",
      "Epoch 76/100, Loss: 1.011166962644287\n",
      "Epoch 77/100, Loss: 1.0112837496077178\n",
      "Epoch 78/100, Loss: 1.0107281776133237\n",
      "Epoch 79/100, Loss: 1.010869268541503\n",
      "Epoch 80/100, Loss: 1.0108867838314384\n",
      "Epoch 81/100, Loss: 1.010836435783251\n",
      "Epoch 82/100, Loss: 1.010850169324571\n",
      "Epoch 83/100, Loss: 1.0109962830308137\n",
      "Epoch 84/100, Loss: 1.0110133792991471\n",
      "Epoch 85/100, Loss: 1.010753843454039\n",
      "Epoch 86/100, Loss: 1.0108011752272108\n",
      "Epoch 87/100, Loss: 1.0116013790486724\n",
      "Epoch 88/100, Loss: 1.010888913814809\n",
      "Epoch 89/100, Loss: 1.0110361882123597\n",
      "Epoch 90/100, Loss: 1.0106853723288722\n",
      "Epoch 91/100, Loss: 1.011142063748305\n",
      "Epoch 92/100, Loss: 1.0110003116024529\n",
      "Epoch 93/100, Loss: 1.0108557718289886\n",
      "Epoch 94/100, Loss: 1.0110942753019987\n",
      "Epoch 95/100, Loss: 1.0109925335569747\n",
      "Epoch 96/100, Loss: 1.0111035061490004\n",
      "Epoch 97/100, Loss: 1.0106890943921676\n",
      "Epoch 98/100, Loss: 1.011035615015941\n",
      "Epoch 99/100, Loss: 1.011267661160914\n",
      "Epoch 100/100, Loss: 1.0111757748588255\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loss_values, pred_values, target_values\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss_values\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n",
      "File \u001b[0;32m~/firsttry/main.py:154\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m    153\u001b[0m loss_values \u001b[38;5;241m=\u001b[39m train_model(model, train_data, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m--> 154\u001b[0m loss_values \u001b[38;5;241m=\u001b[39m \u001b[43mloss_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m()\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m    157\u001b[0m epochs_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from main import loss_values, pred_values, target_values\n",
    "for t in loss_values:\n",
    "    print(t.)\n",
    "print(loss_values.device)\n",
    "\n",
    "# \n",
    "epochs_range = range(100)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs_range, loss_values, marker='o', linestyle='-', color='b', label='Loss')\n",
    "plt.title('Training Loss Curve', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('training_loss_curve.png')\n",
    "\n",
    "# \n",
    "\n",
    "pred_values, target_values = pred_values.cpu(), target_values.cpu()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f23c2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc8ebca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original GPU Tensor List:\n",
      "tensor([1, 2, 3], device='cuda:0') cuda:0\n",
      "tensor([4, 5, 6], device='cuda:0') cuda:0\n",
      "\n",
      "Migrated CPU Tensor List:\n",
      "tensor([1, 2, 3]) cpu\n",
      "tensor([4, 5, 6]) cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#  GPU  Tensor List\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tensor_list_gpu = [torch.tensor([1, 2, 3], device=device), torch.tensor([4, 5, 6], device=device)]\n",
    "\n",
    "#  GPU Tensor  CPU\n",
    "tensor_list_cpu = [t.cpu() for t in tensor_list_gpu]\n",
    "\n",
    "# \n",
    "print(\"Original GPU Tensor List:\")\n",
    "for t in tensor_list_gpu:\n",
    "    print(t, t.device)\n",
    "\n",
    "print(\"\\nMigrated CPU Tensor List:\")\n",
    "for t in tensor_list_cpu:\n",
    "    print(t, t.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d04fbb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def han():\n",
    "    print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc90b83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([110, 64]) torch.Size([110, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# GRU Model\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_1, _ = self.gru(x)\n",
    "        # Take the output of the last time step\n",
    "        out_2 = self.fc(out_1)  \n",
    "        return out_1,out_2\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 20  # Each node feature is 20-dimensional\n",
    "hidden_size = 64\n",
    "output_size = 1  # Output for each node (or aggregated output)\n",
    "num_layers = 2\n",
    "learning_rate = 0.001\n",
    "num_nodes = 110  # Number of nodes (example size)\n",
    "epochs = 50\n",
    "x = torch.randn(110,20)\n",
    "y = torch.rand(110)\n",
    "\n",
    "model = GRUModel(input_size, hidden_size, output_size, num_layers)\n",
    "a,b = model.forward(x)\n",
    "print(a.shape, b.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f73f44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0530, -0.3955, -0.8346,  0.5348,  0.2964, -0.7354,  0.7210, -1.1561,\n",
      "         0.4831,  0.0539,  0.9434, -0.9038, -1.0901,  0.1797,  1.5278, -0.5643,\n",
      "         0.0918,  0.3521,  1.1762, -0.5371]) tensor([-1.2511,  0.3673,  1.6838, -0.0270,  1.1019, -0.6602, -0.1400,  0.3115,\n",
      "        -0.2202, -0.1501, -1.0527,  1.1789, -1.8414,  1.4203,  1.8792,  1.3221,\n",
      "         0.9199,  0.6296,  0.3717,  0.3932])\n",
      "tensor(0.0338) tensor(0.9299)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(110,20)\n",
    "y = torch.rand(110)\n",
    "train_data = []\n",
    "train_data.append(x)\n",
    "train_data.append(y)\n",
    "for i in train_data:\n",
    "    x, y= i[0], i[1]\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05643431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.randn(15,20)\n",
    "y = torch.randn(15,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3015c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "folder_path = '/root/firsttry/CMIN/CMIN-US/price/processed/'\n",
    "file_list = [f for f in os.listdir(folder_path) if f.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4806c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVDA.txt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a4c2c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(folder_path, file_list[10]), sep='\\t', header=None, names=['dt', 'open', 'high', 'low', 'close', 'adj close', 'volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe40814c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0.065814</td>\n",
       "      <td>0.042497</td>\n",
       "      <td>0.071178</td>\n",
       "      <td>0.047558</td>\n",
       "      <td>0.065814</td>\n",
       "      <td>91470400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.057129</td>\n",
       "      <td>0.020356</td>\n",
       "      <td>0.043877</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>58326800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>-0.007277</td>\n",
       "      <td>-0.005228</td>\n",
       "      <td>-0.007570</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>58012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>0.030641</td>\n",
       "      <td>0.028993</td>\n",
       "      <td>0.037297</td>\n",
       "      <td>0.035532</td>\n",
       "      <td>0.030641</td>\n",
       "      <td>88121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>-0.005244</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>49700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>-0.020643</td>\n",
       "      <td>-0.101663</td>\n",
       "      <td>-0.071823</td>\n",
       "      <td>-0.011853</td>\n",
       "      <td>-0.020643</td>\n",
       "      <td>71375800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>-0.002950</td>\n",
       "      <td>-0.024299</td>\n",
       "      <td>-0.026900</td>\n",
       "      <td>-0.022154</td>\n",
       "      <td>-0.002950</td>\n",
       "      <td>46184700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>0.048920</td>\n",
       "      <td>0.039150</td>\n",
       "      <td>0.034679</td>\n",
       "      <td>0.009431</td>\n",
       "      <td>0.048920</td>\n",
       "      <td>52438500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.018221</td>\n",
       "      <td>0.014938</td>\n",
       "      <td>0.038247</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>39518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>0.029905</td>\n",
       "      <td>0.017053</td>\n",
       "      <td>0.034518</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>34262400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1002 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dt      open      high       low     close  adj close    volume\n",
       "0     2018-01-03  0.065814  0.042497  0.071178  0.047558   0.065814  91470400\n",
       "1     2018-01-04  0.005271  0.057129  0.020356  0.043877   0.005271  58326800\n",
       "2     2018-01-05  0.008474 -0.007277 -0.005228 -0.007570   0.008474  58012400\n",
       "3     2018-01-08  0.030641  0.028993  0.037297  0.035532   0.030641  88121600\n",
       "4     2018-01-09 -0.000270  0.008258 -0.005244  0.000274  -0.000270  49700000\n",
       "...          ...       ...       ...       ...       ...        ...       ...\n",
       "997   2021-12-17 -0.020643 -0.101663 -0.071823 -0.011853  -0.020643  71375800\n",
       "998   2021-12-20 -0.002950 -0.024299 -0.026900 -0.022154  -0.002950  46184700\n",
       "999   2021-12-21  0.048920  0.039150  0.034679  0.009431   0.048920  52438500\n",
       "1000  2021-12-22  0.011178  0.018221  0.014938  0.038247   0.011178  39518400\n",
       "1001  2021-12-23  0.008163  0.029905  0.017053  0.034518   0.008163  34262400\n",
       "\n",
       "[1002 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e599902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# \n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "#  'close' \n",
    "plt.hist(df['close'], bins=10, alpha=0.5, label='Close', color='blue', edgecolor='black')\n",
    "\n",
    "#  'adj close' \n",
    "plt.hist(df['adj close'], bins=10, alpha=0.5, label='Adj Close', color='red', edgecolor='black')\n",
    "\n",
    "# \n",
    "plt.title('Distribution of Close and Adjusted Close')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# \n",
    "plt.legend()\n",
    "\n",
    "# \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae480a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = '/root/firsttry/CMIN/CMIN-US/price/raw/AAPL.csv'\n",
    "df_raw = pd.read_csv(p1)\n",
    "p2 = '/root/firsttry/CMIN/CMIN-US/price/processed/AAPL.txt'\n",
    "df_prod = pd.read_csv(p2, sep='\\t', header=None, names=['dt', 'open', 'high', 'low', 'close', 'adj close', 'volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78b4315e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              NaN\n",
       "1        43.064999\n",
       "2        43.057499\n",
       "3        43.257500\n",
       "4        43.750000\n",
       "           ...    \n",
       "1003    176.279999\n",
       "1004    180.330002\n",
       "1005    179.289993\n",
       "1006    179.380005\n",
       "1007    178.199997\n",
       "Name: Close, Length: 1008, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['Close'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12012f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            NaN\n",
       "1      -0.000174\n",
       "2       0.004645\n",
       "3       0.011385\n",
       "4      -0.003714\n",
       "          ...   \n",
       "1003    0.022975\n",
       "1004   -0.005767\n",
       "1005    0.000502\n",
       "1006   -0.006578\n",
       "1007   -0.003535\n",
       "Name: Close, Length: 1008, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_raw['Close'] - df_raw['Close'].shift(1)) / df_raw['Close'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e960a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.013928</td>\n",
       "      <td>0.013059</td>\n",
       "      <td>0.015952</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>118071600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>-0.006187</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>89738400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>0.010953</td>\n",
       "      <td>0.005637</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>94640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>-0.003714</td>\n",
       "      <td>0.005247</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>-0.003714</td>\n",
       "      <td>82271200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>-0.003132</td>\n",
       "      <td>-0.002990</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>86336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>-0.006502</td>\n",
       "      <td>-0.052153</td>\n",
       "      <td>-0.042343</td>\n",
       "      <td>-0.006208</td>\n",
       "      <td>-0.006502</td>\n",
       "      <td>195432700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>-0.008122</td>\n",
       "      <td>-0.009710</td>\n",
       "      <td>-0.016660</td>\n",
       "      <td>-0.013142</td>\n",
       "      <td>-0.008122</td>\n",
       "      <td>107499100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>0.019087</td>\n",
       "      <td>0.019491</td>\n",
       "      <td>0.015359</td>\n",
       "      <td>0.009913</td>\n",
       "      <td>0.019087</td>\n",
       "      <td>91185900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>0.015319</td>\n",
       "      <td>0.008627</td>\n",
       "      <td>0.015358</td>\n",
       "      <td>0.017916</td>\n",
       "      <td>0.015319</td>\n",
       "      <td>92135300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.016239</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>0.018124</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>68227500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1002 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dt      open      high       low     close  adj close     volume\n",
       "0     2018-01-03 -0.000174  0.013928  0.013059  0.015952  -0.000174  118071600\n",
       "1     2018-01-04  0.004645  0.000058 -0.006187  0.000698   0.004645   89738400\n",
       "2     2018-01-05  0.011385  0.005216  0.010953  0.005637   0.011385   94640000\n",
       "3     2018-01-08 -0.003714  0.005247  0.001369  0.005085  -0.003714   82271200\n",
       "4     2018-01-09 -0.000115  0.001147 -0.003132 -0.002990  -0.000115   86336000\n",
       "...          ...       ...       ...       ...       ...        ...        ...\n",
       "997   2021-12-17 -0.006502 -0.052153 -0.042343 -0.006208  -0.006502  195432700\n",
       "998   2021-12-20 -0.008122 -0.009710 -0.016660 -0.013142  -0.008122  107499100\n",
       "999   2021-12-21  0.019087  0.019491  0.015359  0.009913   0.019087   91185900\n",
       "1000  2021-12-22  0.015319  0.008627  0.015358  0.017916   0.015319   92135300\n",
       "1001  2021-12-23  0.003644  0.016239  0.005630  0.018124   0.003644   68227500\n",
       "\n",
       "[1002 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace0c4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firsttry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
