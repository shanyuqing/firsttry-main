{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e1edabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbcdb257",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = 'CMIN/CMIN-US/price/raw/BABA.csv'\n",
    "df1 = pd.read_csv(f_path)\n",
    "df1['Date'] = pd.to_datetime(df1['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a1fcba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_path = 'CMIN/CMIN-US/price/raw/BAC.csv'\n",
    "df2 = pd.read_csv(f_path)\n",
    "df2['Date'] = pd.to_datetime(df2['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cd1404f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df = pd.merge(df1[['Date','Close']], df2[['Date','Close']], on='Date', how='inner', suffixes=('_BABA', '_BAC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b14068",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_df.set_index('Date', inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18b9e6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a82a5b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuqin\\AppData\\Local\\Temp\\ipykernel_4840\\275173771.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  merge_df['Close_BAC'] = merge_df['Close_BAC']/ merge_df['Close_BAC'][0]\n",
      "C:\\Users\\yuqin\\AppData\\Local\\Temp\\ipykernel_4840\\275173771.py:2: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  merge_df['Close_BABA'] = merge_df['Close_BABA']/ merge_df['Close_BABA'][0]\n"
     ]
    }
   ],
   "source": [
    "merge_df['Close_BAC'] = merge_df['Close_BAC']/ merge_df['Close_BAC'][0]\n",
    "merge_df['Close_BABA'] = merge_df['Close_BABA']/ merge_df['Close_BABA'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baa4259f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Date'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merge_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2af8a0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_BABA</th>\n",
       "      <th>Close_BAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Close_BABA</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.2181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close_BAC</th>\n",
       "      <td>-0.2181</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close_BABA  Close_BAC\n",
       "Close_BABA      1.0000    -0.2181\n",
       "Close_BAC      -0.2181     1.0000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55088f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtn_df = np.log(merge_df).diff(-1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f629acf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_BABA</th>\n",
       "      <th>Close_BAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Close_BABA</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.303503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close_BAC</th>\n",
       "      <td>0.303503</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close_BABA  Close_BAC\n",
       "Close_BABA    1.000000   0.303503\n",
       "Close_BAC     0.303503   1.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtn_df.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "005e6f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close_BABA</th>\n",
       "      <th>Close_BAC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Close_BABA</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.29358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close_BAC</th>\n",
       "      <td>0.29358</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Close_BABA  Close_BAC\n",
       "Close_BABA     1.00000    0.29358\n",
       "Close_BAC      0.29358    1.00000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtn_df.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83c40c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Close_BABA</th>\n",
       "      <th>Close_BAC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2018</th>\n",
       "      <th>Close_BABA</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close_BAC</th>\n",
       "      <td>0.436550</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2019</th>\n",
       "      <th>Close_BABA</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.465117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close_BAC</th>\n",
       "      <td>0.465117</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2020</th>\n",
       "      <th>Close_BABA</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.353892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close_BAC</th>\n",
       "      <td>0.353892</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2021</th>\n",
       "      <th>Close_BABA</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.101842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close_BAC</th>\n",
       "      <td>0.101842</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Close_BABA  Close_BAC\n",
       "Date                                  \n",
       "2018 Close_BABA    1.000000   0.436550\n",
       "     Close_BAC     0.436550   1.000000\n",
       "2019 Close_BABA    1.000000   0.465117\n",
       "     Close_BAC     0.465117   1.000000\n",
       "2020 Close_BABA    1.000000   0.353892\n",
       "     Close_BAC     0.353892   1.000000\n",
       "2021 Close_BABA    1.000000   0.101842\n",
       "     Close_BAC     0.101842   1.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rtn_df.groupby(rtn_df.index.year).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0bf21f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Date'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merge_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d874fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL.csv', 'ABBV.csv', 'ABT.csv', 'ACN.csv', 'ADBE.csv', 'ADP.csv', 'AEP.csv', 'AMT.csv', 'AMZN.csv', 'APD.csv', 'ASML.csv', 'AVGO.csv', 'AWK.csv', 'BA.csv', 'BABA.csv', 'BAC.csv', 'BBL.csv', 'BHP.csv', 'BP.csv', 'BRK-A.csv', 'C-PJ.csv', 'CAT.csv', 'CCI.csv', 'CHTR.csv', 'CMCSA.csv', 'COP.csv', 'COST.csv', 'CSCO.csv', 'CTA-PB.csv', 'CVX.csv', 'D.csv', 'DE.csv', 'DEO.csv', 'DHR.csv', 'DIS.csv', 'DLR.csv', 'DUK.csv', 'ECL.csv', 'EL.csv', 'ENB.csv', 'EQIX.csv', 'EQNR.csv', 'EXC.csv', 'FB.csv', 'FCX.csv', 'GE.csv', 'GOOG.csv', 'HD.csv', 'HON.csv', 'JD.csv', 'JNJ.csv', 'JPM.csv', 'KO.csv', 'LLY.csv', 'LOW.csv', 'MA.csv', 'MCD.csv', 'MMM.csv', 'MS.csv', 'MSFT.csv', 'NEE.csv', 'NEM.csv', 'NFLX.csv', 'NGG.csv', 'NKE.csv', 'NVDA.csv', 'NVO.csv', 'NVS.csv', 'O.csv', 'ORCL.csv', 'PEP.csv', 'PFE.csv', 'PG.csv', 'PLD.csv', 'PM.csv', 'PSA.csv', 'PTR.csv', 'PYPL.csv', 'RDS-B.csv', 'RIO.csv', 'RTX.csv', 'SBAC.csv', 'SBUX.csv', 'SCHW.csv', 'SHW.csv', 'snap.csv', 'SNP.csv', 'SO.csv', 'SPG-PJ.csv', 'SRE.csv', 'T.csv', 'TGT.csv', 'TM.csv', 'TMO.csv', 'TMUS.csv', 'TSLA.csv', 'TSM.csv', 'TTE.csv', 'UL.csv', 'UNH.csv', 'Unp.csv', 'UPS.csv', 'V.csv', 'VALE.csv', 'VZ.csv', 'WELL.csv', 'WFC-PL.csv', 'WMT.csv', 'XEL.csv', 'XOM.csv']\n",
      "['AAPL', 'ABBV', 'ABT', 'ACN', 'ADBE', 'ADP', 'AEP', 'AMT', 'AMZN', 'APD', 'ASML', 'AVGO', 'AWK', 'BA', 'BABA', 'BAC', 'BBL', 'BHP', 'BP', 'BRK-A', 'C-PJ', 'CAT', 'CCI', 'CHTR', 'CMCSA', 'COP', 'COST', 'CSCO', 'CTA-PB', 'CVX', 'D', 'DE', 'DEO', 'DHR', 'DIS', 'DLR', 'DUK', 'ECL', 'EL', 'ENB', 'EQIX', 'EQNR', 'EXC', 'FB', 'FCX', 'GE', 'GOOG', 'HD', 'HON', 'JD', 'JNJ', 'JPM', 'KO', 'LLY', 'LOW', 'MA', 'MCD', 'MMM', 'MS', 'MSFT', 'NEE', 'NEM', 'NFLX', 'NGG', 'NKE', 'NVDA', 'NVO', 'NVS', 'O', 'ORCL', 'PEP', 'PFE', 'PG', 'PLD', 'PM', 'PSA', 'PTR', 'PYPL', 'RDS-B', 'RIO', 'RTX', 'SBAC', 'SBUX', 'SCHW', 'SHW', 'snap', 'SNP', 'SO', 'SPG-PJ', 'SRE', 'T', 'TGT', 'TM', 'TMO', 'TMUS', 'TSLA', 'TSM', 'TTE', 'UL', 'UNH', 'Unp', 'UPS', 'V', 'VALE', 'VZ', 'WELL', 'WFC-PL', 'WMT', 'XEL', 'XOM']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the directory\n",
    "directory = 'CMIN/CMIN-US/price/raw/'\n",
    "\n",
    "# List all files in the directory\n",
    "filenames = os.listdir(directory)\n",
    "\n",
    "print(filenames)\n",
    "company_list = []\n",
    "for filename in filenames:\n",
    "    filename = filename[:-4]\n",
    "    company_list.append(filename)\n",
    "print(company_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "386e32f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key='sk-Hdf6Ybl_685eMpO2-wbhke_SblUC65NaULFM2cfOkHT3BlbkFJVcE21Wnb_pHC7uBq4bbgEq8GiWNcwuoXVrc7BhIwYA')\n",
    "\n",
    "# Function to get the correlation between two companies\n",
    "def query_gpt_for_correlation(sentence):\n",
    "    systemPrompt = f\"\"\"Based on fundamental information, estimate the correlation coefficient of the following stocks. \n",
    "    You need to answer with a floating-point number between the range [-1,1], where 1 represents perfect positive correlation, -1 represents perfect negative correlation, and 0 represents no correlation.\n",
    "    For example: \n",
    "                Sample Input: [BAC, BABA]\n",
    "                Sample Output: Value: -0.22, Explanation:Bank of America (BAC) operates in the financial sector, while Alibaba (BABA) is in e-commerce and technology;BAC's performance is heavily influenced by the U.S. economy and financial markets, while BABA is more tied to the Chinese economy and global e-commerce;While both companies may react to global economic factors, their sensitivity to specific economic policies, such as interest rates or trade policies, differs.\n",
    "                Sample Input: [TSLA, AAPL]\n",
    "                Sample Output: Value: 0.25, Explanation: Both Tesla (TSLA) and Apple (AAPL) are tech-driven companies, which means they both tend to move similarly when the broader technology sector is affected by investor sentiment or market conditions;Tesla operates in the electric vehicle and renewable energy space, while Apple is focused on consumer electronics;Both stocks are high-growth companies and are often included in tech-focused investment portfolios. Positive or negative sentiment around tech stocks can lead to both moving in the same direction, contributing to a moderate correlation. \n",
    "\"\"\"\n",
    "    prompt = sentence\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": systemPrompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=1500,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b76bbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list=company_list[:20]\n",
    "n_company =len(company_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ce816e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# from tqdm import trange\n",
    "# import time\n",
    "# test = range(10)\n",
    "# # 写一个trange demo\n",
    "# for i in trange(10):\n",
    "#     time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5968de8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [ABBV, AAPL] 0.15\n",
      "Input: [ABT, AAPL] 0.15\n",
      "Input: [ABT, ABBV] 0.67\n",
      "Input: [ACN, AAPL] 0.35\n",
      "Input: [ACN, ABBV] 0.1\n",
      "Input: [ACN, ABT] 0.15\n",
      "Input: [ADBE, AAPL] 0.65\n",
      "Input: [ADBE, ABBV] 0.15\n",
      "Input: [ADBE, ABT] 0.15\n",
      "Input: [ADBE, ACN] 0.68\n",
      "Input: [ADP, AAPL] 0.15\n",
      "Input: [ADP, ABBV] 0.15\n",
      "Input: [ADP, ABT] 0.15\n",
      "Input: [ADP, ACN] 0.6\n",
      "Input: [ADP, ADBE] 0.35\n",
      "Input: [AEP, AAPL] 0.15\n",
      "Input: [AEP, ABBV] 0.15\n",
      "Input: [AEP, ABT] 0.1\n",
      "Input: [AEP, ACN] 0.15\n",
      "Input: [AEP, ADBE] 0.15\n",
      "Input: [AEP, ADP] 0.15\n",
      "Input: [AMT, AAPL] 0.4\n",
      "Input: [AMT, ABBV] 0.15\n",
      "Input: [AMT, ABT] 0.1\n",
      "Input: [AMT, ACN] 0.35\n",
      "Input: [AMT, ADBE] 0.35\n",
      "Input: [AMT, ADP] 0.35\n",
      "Input: [AMT, AEP] 0.15\n",
      "Input: [AMZN, AAPL] 0.35\n",
      "Input: [AMZN, ABBV] 0.05\n",
      "Input: [AMZN, ABT] 0.15\n",
      "Input: [AMZN, ACN] 0.35\n",
      "Input: [AMZN, ADBE] 0.35\n",
      "Input: [AMZN, ADP] 0.15\n",
      "Input: [AMZN, AEP] -0.15\n",
      "Input: [AMZN, AMT] 0.3\n",
      "Input: [APD, AAPL] 0.15\n",
      "Input: [APD, ABBV] 0.15\n",
      "Input: [APD, ABT] 0.1\n",
      "Input: [APD, ACN] 0.15\n",
      "Input: [APD, ADBE] 0.15\n",
      "Input: [APD, ADP] 0.15\n",
      "Input: [APD, AEP] 0.15\n",
      "Input: [APD, AMT] 0.15\n",
      "Input: [APD, AMZN] 0.15\n",
      "Input: [ASML, AAPL] 0.45\n",
      "Input: [ASML, ABBV] 0.1\n",
      "Input: [ASML, ABT] 0.15\n",
      "Input: [ASML, ACN] 0.35\n",
      "Input: [ASML, ADBE] 0.35\n",
      "Input: [ASML, ADP] 0.15\n",
      "Input: [ASML, AEP] -0.15\n",
      "Input: [ASML, AMT] 0.15\n",
      "Input: [ASML, AMZN] 0.35\n",
      "Input: [ASML, APD] 0.15\n",
      "Input: [AVGO, AAPL] 0.55\n",
      "Input: [AVGO, ABBV] 0.1\n",
      "Input: [AVGO, ABT] 0.15\n",
      "Input: [AVGO, ACN] 0.45\n",
      "Input: [AVGO, ADBE] 0.35\n",
      "Input: [AVGO, ADP] 0.4\n",
      "Input: [AVGO, AEP] -0.15\n",
      "Input: [AVGO, AMT] 0.15\n",
      "Input: [AVGO, AMZN] 0.3\n",
      "Input: [AVGO, APD] 0.15\n",
      "Input: [AVGO, ASML] 0.65\n",
      "Input: [AWK, AAPL] 0.15\n",
      "Input: [AWK, ABBV] 0.1\n",
      "Input: [AWK, ABT] 0.15\n",
      "Input: [AWK, ACN] 0.15\n",
      "Input: [AWK, ADBE] 0.15\n",
      "Input: [AWK, ADP] 0.1\n",
      "Input: [AWK, AEP] 0.55\n",
      "Input: [AWK, AMT] 0.35\n",
      "Input: [AWK, AMZN] 0.15\n",
      "Input: [AWK, APD] 0.2\n",
      "Input: [AWK, ASML] 0.1\n",
      "Input: [AWK, AVGO] 0.1\n",
      "Input: [BA, AAPL] 0.15\n",
      "Input: [BA, ABBV] -0.15\n",
      "Input: [BA, ABT] 0.1\n",
      "Input: [BA, ACN] 0.15\n",
      "Input: [BA, ADBE] 0.15\n",
      "Input: [BA, ADP] 0.1\n",
      "Input: [BA, AEP] -0.15\n",
      "Input: [BA, AMT] -0.15\n",
      "Input: [BA, AMZN] -0.1\n",
      "Input: [BA, APD] 0.15\n",
      "Input: [BA, ASML] 0.15\n",
      "Input: [BA, AVGO] 0.15\n",
      "Input: [BA, AWK] -0.15\n",
      "Input: [BABA, AAPL] 0.35\n",
      "Input: [BABA, ABBV] -0.15\n",
      "Input: [BABA, ABT] -0.15\n",
      "Input: [BABA, ACN] 0.15\n",
      "Input: [BABA, ADBE] 0.35\n",
      "Input: [BABA, ADP] -0.15\n",
      "Input: [BABA, AEP] -0.15\n",
      "Input: [BABA, AMT] -0.15\n",
      "Input: [BABA, AMZN] 0.5\n",
      "Input: [BABA, APD] -0.15\n",
      "Input: [BABA, ASML] 0.35\n",
      "Input: [BABA, AVGO] 0.35\n",
      "Input: [BABA, AWK] -0.15\n",
      "Input: [BABA, BA] 0.05\n",
      "Input: [BAC, AAPL] 0.15\n",
      "Input: [BAC, ABBV] -0.1\n",
      "Input: [BAC, ABT] -0.1\n",
      "Input: [BAC, ACN] 0.15\n",
      "Input: [BAC, ADBE] 0.15\n",
      "Input: [BAC, ADP] 0.45\n",
      "Input: [BAC, AEP] 0.1\n",
      "Input: [BAC, AMT] -0.15\n",
      "Input: [BAC, AMZN] -0.15\n",
      "Input: [BAC, APD] 0.15\n",
      "Input: [BAC, ASML] 0.15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m company2 \u001b[38;5;241m=\u001b[39m company_pairs[i][\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     19\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompany\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompany2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 20\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mquery_gpt_for_correlation\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m correlation_value \u001b[38;5;241m=\u001b[39m get_value(response)\n\u001b[0;32m     22\u001b[0m correlation_value_list\u001b[38;5;241m.\u001b[39mappend(correlation_value)\n",
      "Cell \u001b[1;32mIn[5], line 15\u001b[0m, in \u001b[0;36mquery_gpt_for_correlation\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      6\u001b[0m     systemPrompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mBased on fundamental information, estimate the correlation coefficient of the following stocks. \u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m    You need to answer with a floating-point number between the range [-1,1], where 1 represents perfect positive correlation, -1 represents perfect negative correlation, and 0 represents no correlation.\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m    For example: \u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m                Sample Output: Value: 0.25, Explanation: Both Tesla (TSLA) and Apple (AAPL) are tech-driven companies, which means they both tend to move similarly when the broader technology sector is affected by investor sentiment or market conditions;Tesla operates in the electric vehicle and renewable energy space, while Apple is focused on consumer electronics;Both stocks are high-growth companies and are often included in tech-focused investment portfolios. Positive or negative sentiment around tech stocks can lead to both moving in the same direction, contributing to a moderate correlation. \u001b[39m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     14\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m sentence\n\u001b[1;32m---> 15\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystemPrompt\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\openai\\_utils\\_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\openai\\resources\\chat\\completions.py:704\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    701\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    702\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    703\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    708\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    735\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\openai\\_base_client.py:1270\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1257\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1258\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1265\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1267\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1268\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1269\u001b[0m     )\n\u001b[1;32m-> 1270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\openai\\_base_client.py:947\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    945\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 947\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    950\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    951\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\openai\\_base_client.py:983\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m    980\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 983\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    984\u001b[0m         request,\n\u001b[0;32m    985\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    987\u001b[0m     )\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    989\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpx\\_client.py:926\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    924\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 926\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpx\\_client.py:954\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    951\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 954\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    959\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpx\\_client.py:991\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    989\u001b[0m     hook(request)\n\u001b[1;32m--> 991\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpx\\_client.py:1027\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1027\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1031\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpx\\_transports\\default.py:236\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    223\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    224\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    225\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    234\u001b[0m )\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 236\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    241\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    242\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    243\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    244\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    245\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpcore\\_sync\\http_proxy.py:344\u001b[0m, in \u001b[0;36mTunnelHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;241m=\u001b[39m HTTP11Connection(\n\u001b[0;32m    338\u001b[0m                 origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remote_origin,\n\u001b[0;32m    339\u001b[0m                 stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    340\u001b[0m                 keepalive_expiry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keepalive_expiry,\n\u001b[0;32m    341\u001b[0m             )\n\u001b[0;32m    343\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpcore\\_sync\\http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpcore\\_sync\\http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    107\u001b[0m     (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m         trailing_data,\n\u001b[1;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m         http_version,\n\u001b[0;32m    116\u001b[0m         status,\n\u001b[0;32m    117\u001b[0m         reason_phrase,\n\u001b[0;32m    118\u001b[0m         headers,\n\u001b[0;32m    119\u001b[0m     )\n\u001b[0;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpcore\\_sync\\http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define a function to extract the correlation value from the response\n",
    "def get_value(sample):\n",
    "    import re\n",
    "    pattern = r'Value: (-?\\d+\\.\\d+)'\n",
    "    match = re.search(pattern, sample)\n",
    "    value= float(match.group(1))\n",
    "    return value\n",
    "\n",
    "correlation_value_list = []\n",
    "company_pairs = []\n",
    "for i in range(n_company):\n",
    "    for j in range(i+1):\n",
    "        if i != j:\n",
    "            company_pairs.append([company_list[i], company_list[j]])\n",
    "\n",
    "for i in range(len(company_pairs)):\n",
    "    company = company_pairs[i][0]\n",
    "    company2 = company_pairs[i][1]\n",
    "    sentence = f\"Input: [{company}, {company2}]\"\n",
    "    response = query_gpt_for_correlation(sentence)\n",
    "    correlation_value = get_value(response)\n",
    "    correlation_value_list.append(correlation_value)\n",
    "    print(sentence, correlation_value)\n",
    "\n",
    "# 创建相关系数矩阵\n",
    "import pandas as pd\n",
    "\n",
    "# 加载CSV数据\n",
    "data = pd.read_csv(r'C:\\Users\\yuqin\\firsttry\\correlation_df.csv')\n",
    "\n",
    "# 清理并提取公司对和相关系数\n",
    "data['Company'] = data['Company'].apply(lambda x: eval(x))  # 将字符串转换为列表\n",
    "data['Company1'] = data['Company'].apply(lambda x: x[0])\n",
    "data['Company2'] = data['Company'].apply(lambda x: x[1])\n",
    "\n",
    "# 创建矩阵格式的透视表\n",
    "matrix_df = data.pivot_table(index='Company1', columns='Company2', values='Correlation')\n",
    "\n",
    "# 通过镜像矩阵来填补缺失值（因为相关性是对称的）\n",
    "matrix_df = matrix_df.combine_first(matrix_df.T)\n",
    "\n",
    "# 对角线填入1（公司与自身的相关性为1）\n",
    "for company in matrix_df.columns:\n",
    "    matrix_df.loc[company, company] = 1.0\n",
    "matrix_df.to_csv(r'C:\\Users\\yuqin\\firsttry\\correlation_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e1fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construct graph\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "# Create a DataFrame to store the correlation values\n",
    "correlation_df = pd.DataFrame(correlation_value_list, columns=['Correlation'])\n",
    "correlation_df['Company'] = company_pairs\n",
    "correlation_df = correlation_df[['Company', 'Correlation']]\n",
    "correlation_df.to_csv('correlation_df.csv', index=False)\n",
    "print(correlation_df)\n",
    "\n",
    "import networkx as nx   \n",
    "import matplotlib.pyplot as plt\n",
    "# Create a graph object\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "for company in company_list:\n",
    "    G.add_node(company)\n",
    "\n",
    "# Add edges to the graph\n",
    "for i in range(len(company_pairs)):\n",
    "    company1 = company_pairs[i][0]\n",
    "    company2 = company_pairs[i][1]\n",
    "    correlation = correlation_value_list[i]\n",
    "    # if abs(correlation) > 0.5:\n",
    "    #     G.add_edge(company1, company2, weight=correlation)\n",
    "    G.add_edge(company1, company2, weight=correlation)\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(12, 12))\n",
    "pos = nx.spring_layout(G)\n",
    "\n",
    "# Draw edges with weights\n",
    "edges = G.edges(data=True)\n",
    "nx.draw_networkx_edges(G, pos, edgelist=edges, width=[d['weight'] for (u, v, d) in edges])\n",
    "\n",
    "# Draw nodes and labels\n",
    "nx.draw_networkx_nodes(G, pos, node_size=500, node_color='skyblue')\n",
    "nx.draw_networkx_labels(G, pos, font_size=10, font_color='black')\n",
    "\n",
    "# Draw edge labels\n",
    "edge_labels = {(u, v): f\"{d['weight']:.2f}\" for (u, v, d) in edges}\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "nx.draw(G, pos, with_labels=True, font_size=10, node_size=500, node_color='skyblue', edge_color='black', linewidths=1, font_color='black')\n",
    "plt.title('Stock Correlation Network')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be1148e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "c=[]\n",
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "c.append(a)\n",
    "c.append(b)\n",
    "c = torch.tensor(c, dtype=torch.long).t().contiguous()\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae30ba11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a=1\n",
    "b=2\n",
    "c=3\n",
    "d=[]\n",
    "d.append(a)\n",
    "d.append(b)\n",
    "d.append(c)\n",
    "d = torch.tensor(d, dtype=torch.float)\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d7b1cdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat2 must be a matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m c\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 矩阵相乘\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m e\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m e\n\u001b[0;32m      6\u001b[0m e\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat2 must be a matrix"
     ]
    }
   ],
   "source": [
    "c=torch.randn(2,3)\n",
    "c\n",
    "# 矩阵相乘\n",
    "e=torch.mm(c,d)\n",
    "e\n",
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8555066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.74224809e-04  1.39280439e-02  1.30586184e-02  1.59518614e-02\n",
      "   -1.74155351e-04  1.18071600e+08]\n",
      "  [ 4.64488613e-03  5.79145656e-05 -6.18736165e-03  6.97790151e-04\n",
      "    4.64497485e-03  8.97384000e+07]\n",
      "  [ 1.13854524e-02  5.21625155e-03  1.09528795e-02  5.63693631e-03\n",
      "    1.13853089e-02  9.46400000e+07]\n",
      "  ...\n",
      "  [ 1.97719146e-02  1.54316117e-02  2.12923892e-02  1.53855948e-02\n",
      "    1.97720798e-02  1.52648800e+08]\n",
      "  [-3.24071766e-03  1.55939885e-02  6.07612464e-03  1.10663181e-02\n",
      "   -3.24076661e-03  1.55712400e+08]\n",
      "  [-1.51341015e-03  8.93288626e-04  7.75709237e-04 -6.17422528e-04\n",
      "   -1.51356018e-03  1.51128400e+08]]\n",
      "\n",
      " [[ 1.56491005e-02  1.45151741e-02  1.21334275e-02  1.33333437e-02\n",
      "    1.56487444e-02  4.70230000e+06]\n",
      "  [-5.70285542e-03  1.54236119e-02  1.99850154e-04  3.16194407e-03\n",
      "   -5.70285160e-03  3.57900000e+06]\n",
      "  [ 1.74077477e-02 -7.29493355e-03  1.07869953e-02  2.13523136e-03\n",
      "    1.74079699e-02  4.59930000e+06]\n",
      "  ...\n",
      "  [ 2.34950216e-02  7.26284073e-03  2.01995058e-02  1.83933785e-02\n",
      "    2.34947453e-02  4.47350000e+06]\n",
      "  [-2.69870889e-02  1.62656330e-02  2.30035325e-03 -7.39244785e-03\n",
      "   -2.69869917e-02  4.75430000e+06]\n",
      "  [-2.05480260e-02 -1.82328110e-02 -1.63934426e-02 -2.01422217e-02\n",
      "   -2.05479449e-02  6.66000000e+06]]\n",
      "\n",
      " [[ 2.21124794e-03  1.35739001e-02 -3.04055738e-03  8.47459357e-03\n",
      "    2.21120935e-03  5.68370000e+06]\n",
      "  [-1.69741054e-03  8.64549894e-03  9.82714334e-03  7.71732108e-03\n",
      "   -1.69718268e-03  6.24000000e+06]\n",
      "  [ 2.89036995e-03 -7.73107563e-03 -8.55701371e-03 -2.04218863e-03\n",
      "    2.89020741e-03  5.83690000e+06]\n",
      "  ...\n",
      "  [ 1.37331321e-02  1.08071596e-02  1.42282888e-02  1.27161750e-02\n",
      "    1.37330433e-02  5.36420000e+06]\n",
      "  [ 3.30435197e-04  1.48680084e-02  1.07278759e-02  1.10497070e-02\n",
      "    3.30414676e-04  6.74770000e+06]\n",
      "  [-3.63351630e-03 -1.31690535e-03 -1.95955252e-03 -3.47738042e-03\n",
      "   -3.63331137e-03  8.32570000e+06]]\n",
      "\n",
      " [[ 4.61509342e-03 -3.32244300e-03  5.77546376e-03  1.37456474e-03\n",
      "    4.61523023e-03  2.06420000e+06]\n",
      "  [ 1.18410961e-02  1.31380805e-02  1.20652683e-02  1.16347405e-02\n",
      "    1.18408409e-02  1.77700000e+06]\n",
      "  [ 8.24911307e-03  1.03871032e-02  5.48259591e-03  8.78723890e-03\n",
      "    8.24909169e-03  1.59760000e+06]\n",
      "  ...\n",
      "  [ 1.09851324e-02  1.68839286e-02  1.09168903e-02  1.62175080e-02\n",
      "    1.09850140e-02  1.78280000e+06]\n",
      "  [-1.32938761e-02  5.98215089e-03  4.55014252e-03 -2.27102262e-03\n",
      "   -1.32936866e-02  1.82080000e+06]\n",
      "  [-9.47387548e-03 -1.15291806e-02 -7.18687635e-03 -9.84316192e-03\n",
      "   -9.47405704e-03  2.00220000e+06]]\n",
      "\n",
      " [[ 1.87957009e-02  1.22262947e-02  2.30033517e-02  1.39221846e-02\n",
      "    1.87957009e-02  2.56120000e+06]\n",
      "  [ 1.20415824e-02  2.20786124e-02  1.19302821e-02  2.21722120e-02\n",
      "    1.20415824e-02  2.21140000e+06]\n",
      "  [ 1.15707619e-02  1.68746612e-02  9.99671857e-03  1.04602181e-02\n",
      "    1.15707619e-02  2.37650000e+06]\n",
      "  ...\n",
      "  [ 1.14903640e-02  3.46194886e-02  1.22509630e-02  2.92656390e-02\n",
      "    1.14903640e-02  2.41870000e+06]\n",
      "  [-1.56963804e-02  3.31303906e-03  1.93072281e-03 -4.82650781e-03\n",
      "   -1.56963804e-02  2.33080000e+06]\n",
      "  [ 1.48452251e-03 -6.13237874e-03  3.19612247e-03  4.08166146e-03\n",
      "    1.48452251e-03  2.35690000e+06]]]\n"
     ]
    }
   ],
   "source": [
    "# 读取pkl文件\n",
    "import pickle\n",
    "with open('stock_data.pkl', 'rb') as f:\n",
    "    correlation_matrix = pickle.load(f)\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590f2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1980, 8)\n",
      "(20, 99, 6)\n",
      "[Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20])]\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from model_first import construct_graph\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "\n",
    "def create_data(stock_data, correlation_matrix, window=20, batch_size=32):\n",
    "    num_stocks, num_time_steps, num_features = stock_data.shape\n",
    "\n",
    "    # 数据标准化\n",
    "    scaler = StandardScaler()\n",
    "     # 对整个 stock_data 进行了标准化，stock_data 是形状为 (num_stocks, num_time_steps, num_features) \n",
    "    stock_data = scaler.fit_transform(stock_data.reshape(-1, num_features)).reshape(num_stocks, num_time_steps, num_features)\n",
    "   \n",
    "    \n",
    "    # 初始化存储批次数据的列表\n",
    "    batch_data_list = []\n",
    "\n",
    "    # 滚动窗口生成批次\n",
    "    for start in range(num_time_steps - window):\n",
    "\n",
    "        # 当前窗口的节点特征：过去20天的收盘价\n",
    "        node_features = torch.tensor(stock_data[:, start:start + window, 3], dtype=torch.float32)  # 使用收盘价作为节点特征\n",
    "        node_features = node_features.view(num_stocks, window)\n",
    "\n",
    "        # 创建图的边和边特征\n",
    "        edge_index, edge_attr = construct_graph(correlation_matrix, threshold=0.1)\n",
    "\n",
    "        # 目标值：窗口结束后的第一个时间步的收盘价\n",
    "        y = torch.tensor(stock_data[:, start + window, 3], dtype=torch.float32)\n",
    "\n",
    "        # 创建图数据对象 Data((num_nodes, time_step=20), torch.Size([2, num_edges]), torch.Size([num_edges]), (num_nodes, num_targets=1))\n",
    "        data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "    \n",
    "        # 将数据对象添加到批次列表\n",
    "        batch_data_list.append(data)\n",
    "\n",
    "    # 返回一个包含num_stocks*batch_size个图数据对象的列表\n",
    "    print(batch_data_list)\n",
    "    return batch_data_list\n",
    "\n",
    "\n",
    "\n",
    "# 读取数据\n",
    "import pickle\n",
    "with open('my_data.pkl', 'rb') as f:\n",
    "    my_data = pickle.load(f)\n",
    "print(my_data.shape)\n",
    "\n",
    "#  初始化一个空的三维数组，用于存储股价数据\n",
    "stock_data = np.zeros((20, 99, 6))\n",
    "\n",
    "#  将数据加载到stock_data中,(num_stock, num_days, num_features)\n",
    "for i, stock_code in enumerate(my_data['code'].unique()):\n",
    "    stock_data[i] = my_data[my_data['code'] == stock_code].iloc[:, 1:7].values\n",
    "\n",
    "print(stock_data.shape)\n",
    "# 获取相关系数（值）矩阵\n",
    "correlation_path=r\"C:\\Users\\yuqin\\firsttry\\data\\correlation_matrix.csv\"\n",
    "correlation_matrix = pd.read_csv(correlation_path)\n",
    "correlation_matrix = correlation_matrix.iloc[0:20, 1:21].values\n",
    "\n",
    "batch_data_list = create_data(stock_data, correlation_matrix, window=20, batch_size=32)\n",
    "train_data, test_data = train_test_split(batch_data_list, test_size=0.2, random_state=42)#训练集和测试集如何划分，需要进一步探讨？？\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True) \n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "60e74e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape: torch.Size([640, 20])\n",
      "x shape: torch.Size([32, 20])\n",
      "x shape: torch.Size([620, 20])\n",
      "x shape: torch.Size([31, 20])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def _map_to_global(self, edge_index, batch_index):\n",
    "        # 扩展边索引以映射到全局节点索引\n",
    "        num_nodes = batch_index.size(0)  # 所有节点的总数量\n",
    "        # 创建全局图的节点索引\n",
    "        global_edge_index = edge_index.clone()\n",
    "        # 为每个节点添加偏移量\n",
    "        node_offsets = torch.cumsum(torch.bincount(batch_index), dim=0)\n",
    "        node_offsets = torch.cat([torch.tensor([0], device=edge_index.device), node_offsets[:-1]])\n",
    "\n",
    "        # 映射到全局索引\n",
    "        global_edge_index[0] += node_offsets[batch_index[edge_index[0]]]\n",
    "        global_edge_index[1] += node_offsets[batch_index[edge_index[1]]]\n",
    "    \n",
    "        return global_edge_index\n",
    "for batch in train_loader:\n",
    "    x, edge_index, edge_attr, batch_index = batch.x, batch.edge_index, batch.edge_attr, batch.batch\n",
    "    print(\"x shape:\", x.shape)\n",
    "    x = global_mean_pool(x, batch_index)\n",
    "    print(\"x shape:\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5be10cb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_attr):\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x, edge_index)\n\u001b[1;32m----> 8\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mGCNLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# import model\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# from model import *\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[47], line 4\u001b[0m, in \u001b[0;36mGCNLayer.__init__\u001b[1;34m(self, in_channels, out_channels)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_channels, out_channels):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28msuper\u001b[39m(GCNLayer, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv \u001b[38;5;241m=\u001b[39m \u001b[43mGCNConv\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:210\u001b[0m, in \u001b[0;36mGCNConv.__init__\u001b[1;34m(self, in_channels, out_channels, improved, cached, add_self_loops, normalize, bias, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_adj_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin \u001b[38;5;241m=\u001b[39m \u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    211\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mweight_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mglorot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_channels))\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch_geometric\\nn\\dense\\linear.py:103\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_channels, out_channels, bias, weight_initializer, bias_initializer)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_initializer \u001b[38;5;241m=\u001b[39m weight_initializer\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias_initializer \u001b[38;5;241m=\u001b[39m bias_initializer\n\u001b[1;32m--> 103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43min_channels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_channels, in_channels))\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.conv = GCNConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        return self.conv(x, edge_index)\n",
    "x = GCNLayer(x, edge_index)\n",
    "# import model\n",
    "# from model import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40912a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(640,64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "343058f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (60x5 and 20x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m GCNStockPredictor(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtrainer\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m loss_values \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yuqin\\firsttry\\trainer.py:19\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, epochs, lr)\u001b[0m\n\u001b[0;32m     17\u001b[0m y\u001b[38;5;241m=\u001b[39mbatch\u001b[38;5;241m.\u001b[39my\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 模型预测\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[0;32m     21\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\yuqin\\firsttry\\model.py:69\u001b[0m, in \u001b[0;36mGCNStockPredictor.forward\u001b[1;34m(self, x, edge_index, edge_attr, batch_index)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, edge_attr, batch_index):\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# Step 1: 用Transformer编码历史股价\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     edge_index, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_to_global(edge_index, batch_index)\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;66;03m# Step 2: 用GCN进行节点表示优化\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\yuqin\\firsttry\\model.py:40\u001b[0m, in \u001b[0;36mStockPriceTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# x 是输入的股票历史股价数据 [batch_size*num_stocks, num_features]\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# 变成 [batch_size*num_stocks, num_features, hidden_dim][640,64]\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(x)\u001b[38;5;66;03m#[640,64]\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# 平均池化[batch_size * num_stocks, hidden_dim] 需要池化哪一维度？？？\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\MyFiSt\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (60x5 and 20x64)"
     ]
    }
   ],
   "source": [
    "model = GCNStockPredictor(input_dim=20, hidden_dim=64, num_heads=4, num_layers=2)\n",
    "import trainer\n",
    "loss_values = trainer.train_model(model, train_loader, epochs=50, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9d1848e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 50)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = range(0,50)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c90eb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              dt      open      high       low     close  adj close  \\\n",
      "0     2018-01-03 -0.000174  0.013928  0.013059  0.015952  -0.000174   \n",
      "1     2018-01-04  0.004645  0.000058 -0.006187  0.000698   0.004645   \n",
      "2     2018-01-05  0.011385  0.005216  0.010953  0.005637   0.011385   \n",
      "3     2018-01-08 -0.003714  0.005247  0.001369  0.005085  -0.003714   \n",
      "4     2018-01-09 -0.000115  0.001147 -0.003132 -0.002990  -0.000115   \n",
      "...          ...       ...       ...       ...       ...        ...   \n",
      "1975  2018-05-18 -0.006949 -0.001045 -0.001348 -0.003508  -0.006949   \n",
      "1976  2018-05-21  0.007609 -0.000810  0.004503  0.006055   0.007609   \n",
      "1977  2018-05-22  0.001251  0.003714  0.001763  0.000883   0.001251   \n",
      "1978  2018-05-23 -0.008724 -0.002691 -0.005766 -0.011348  -0.008724   \n",
      "1979  2018-05-24 -0.008662 -0.008499 -0.008328 -0.004869  -0.008662   \n",
      "\n",
      "         volume   code  \n",
      "0     118071600   AAPL  \n",
      "1      89738400   AAPL  \n",
      "2      94640000   AAPL  \n",
      "3      82271200   AAPL  \n",
      "4      86336000   AAPL  \n",
      "...         ...    ...  \n",
      "1975          2  BRK-A  \n",
      "1976          2  BRK-A  \n",
      "1977          2  BRK-A  \n",
      "1978          3  BRK-A  \n",
      "1979          2  BRK-A  \n",
      "\n",
      "[1980 rows x 8 columns]\n",
      "(20, 99, 6)\n",
      "(20, 99)\n"
     ]
    }
   ],
   "source": [
    "# 读取pickle文件\n",
    "import pickle\n",
    "import numpy as np\n",
    "path = r\"C:\\Users\\yuqin\\firsttry\\my_data.pkl\"\n",
    "with open(path, 'rb') as f:\n",
    "    all_data = pickle.load(f)\n",
    "print(all_data)\n",
    "\n",
    "\n",
    "#  初始化一个空的三维数组，用于存储股价数据\n",
    "stock_data = np.zeros((20, 99, 6))\n",
    "\n",
    "#  将数据加载到stock_data中\n",
    "for i, stock_code in enumerate(all_data['code'].unique()):\n",
    "    stock_data[i] = all_data[all_data['code'] == stock_code].iloc[:, 1:7].values\n",
    "print(stock_data.shape)\n",
    "\n",
    "#提取收盘价\n",
    "stock_data = stock_data[:,:,3]\n",
    "print(stock_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95479cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.34570737 0.47283659 0.55249954 0.61009722 0.45695348 0.\n",
      "  0.38312227 0.59880894 0.41630392 0.53720866 0.53197557 0.\n",
      "  0.3536525  0.44786552 0.35994177 0.42345182 0.4155628  0.\n",
      "  0.50295923]\n",
      " [1.         0.40229613 0.4631461  0.37880335 0.42315322 0.\n",
      "  0.30733124 0.         0.3472091  0.33578641 0.35042355 0.\n",
      "  0.33124755 0.         0.36499972 0.31049028 0.30872149 0.\n",
      "  0.44327585]\n",
      " [0.40229613 1.         0.5424515  0.47328888 0.46139523 0.39858058\n",
      "  0.45391007 0.4219725  0.4646266  0.39039319 0.38535399 0.43411242\n",
      "  0.         0.33433266 0.34421573 0.34652557 0.35206444 0.\n",
      "  0.49772766]\n",
      " [0.4631461  0.5424515  1.         0.56879953 0.64562938 0.45750113\n",
      "  0.49728997 0.48639143 0.59132908 0.55691209 0.50245404 0.38512949\n",
      "  0.44161783 0.39750941 0.52887541 0.53784392 0.54263812 0.41485842\n",
      "  0.63924216]\n",
      " [0.37880335 0.47328888 0.56879953 1.         0.51610796 0.\n",
      "  0.32916031 0.6545379  0.38259856 0.59494098 0.50323015 0.\n",
      "  0.3599567  0.47564769 0.         0.37241738 0.36808643 0.\n",
      "  0.41720607]\n",
      " [0.42315322 0.46139523 0.64562938 0.51610796 1.         0.45329495\n",
      "  0.42736645 0.36522701 0.48750622 0.48401564 0.49100961 0.38285526\n",
      "  0.5097011  0.32678872 0.4888225  0.44384241 0.44450306 0.43467955\n",
      "  0.60150504]\n",
      " [0.         0.39858058 0.45750113 0.         0.45329495 1.\n",
      "  0.59272596 0.         0.44357139 0.         0.         0.73676537\n",
      "  0.         0.         0.30857746 0.         0.         0.\n",
      "  0.38710736]\n",
      " [0.30733124 0.45391007 0.49728997 0.32916031 0.42736645 0.59272596\n",
      "  1.         0.         0.42616276 0.         0.         0.59237524\n",
      "  0.         0.         0.30289055 0.         0.         0.\n",
      "  0.37002301]\n",
      " [0.         0.4219725  0.48639143 0.6545379  0.36522701 0.\n",
      "  0.         1.         0.36088744 0.47373911 0.41450173 0.\n",
      "  0.         0.50568213 0.         0.3451527  0.34728246 0.\n",
      "  0.36993494]\n",
      " [0.3472091  0.4646266  0.59132908 0.38259856 0.48750622 0.44357139\n",
      "  0.42616276 0.36088744 1.         0.42786511 0.4121022  0.39415317\n",
      "  0.39711068 0.34726721 0.53638504 0.54337182 0.55310869 0.42282811\n",
      "  0.57374676]\n",
      " [0.33578641 0.39039319 0.55691209 0.59494098 0.48401564 0.\n",
      "  0.         0.47373911 0.42786511 1.         0.63119037 0.\n",
      "  0.42415911 0.45763709 0.38778576 0.52989207 0.53495177 0.37931822\n",
      "  0.50979264]\n",
      " [0.35042355 0.38535399 0.50245404 0.50323015 0.49100961 0.\n",
      "  0.         0.41450173 0.4121022  0.63119037 1.         0.\n",
      "  0.44616867 0.41791623 0.40987432 0.44139767 0.4455359  0.39170777\n",
      "  0.53684823]\n",
      " [0.         0.43411242 0.38512949 0.         0.38285526 0.73676537\n",
      "  0.59237524 0.         0.39415317 0.         0.         1.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.32778517]\n",
      " [0.33124755 0.         0.44161783 0.3599567  0.5097011  0.\n",
      "  0.         0.         0.39711068 0.42415911 0.44616867 0.\n",
      "  1.         0.31509042 0.57220543 0.46880404 0.46425409 0.57866581\n",
      "  0.57026473]\n",
      " [0.         0.33433266 0.39750941 0.47564769 0.32678872 0.\n",
      "  0.         0.50568213 0.34726721 0.45763709 0.41791623 0.\n",
      "  0.31509042 1.         0.30258921 0.39454939 0.40907634 0.\n",
      "  0.40678852]\n",
      " [0.36499972 0.34421573 0.52887541 0.         0.4888225  0.30857746\n",
      "  0.30289055 0.         0.53638504 0.38778576 0.40987432 0.\n",
      "  0.57220543 0.30258921 1.         0.57025269 0.56899016 0.58688599\n",
      "  0.72701315]\n",
      " [0.31049028 0.34652557 0.53784392 0.37241738 0.44384241 0.\n",
      "  0.         0.3451527  0.54337182 0.52989207 0.44139767 0.\n",
      "  0.46880404 0.39454939 0.57025269 1.         0.96683854 0.64469506\n",
      "  0.58216809]\n",
      " [0.30872149 0.35206444 0.54263812 0.36808643 0.44450306 0.\n",
      "  0.         0.34728246 0.55310869 0.53495177 0.4455359  0.\n",
      "  0.46425409 0.40907634 0.56899016 0.96683854 1.         0.6353208\n",
      "  0.583235  ]\n",
      " [0.         0.         0.41485842 0.         0.43467955 0.\n",
      "  0.         0.         0.42282811 0.37931822 0.39170777 0.\n",
      "  0.57866581 0.         0.58688599 0.64469506 0.6353208  1.\n",
      "  0.55662442]\n",
      " [0.44327585 0.49772766 0.63924216 0.41720607 0.60150504 0.38710736\n",
      "  0.37002301 0.36993494 0.57374676 0.50979264 0.53684823 0.32778517\n",
      "  0.57026473 0.40678852 0.72701315 0.58216809 0.583235   0.55662442\n",
      "  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from data.feature_adjacent_matrix import fadj\n",
    "# 将矩阵中小于0.3的值设置为0\n",
    "fadj[fadj<0.3] = 0\n",
    "print(fadj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "485c6275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6369,  0.4135, -0.2983, -0.8699],\n",
      "        [ 1.8241, -0.4960, -0.7140, -0.2375],\n",
      "        [ 0.5532,  1.4378,  1.2707, -1.6193],\n",
      "        [-0.7798,  0.7177, -0.8455,  0.4825]])\n",
      "tensor([[0.0000, 0.4135, 0.0000, 0.0000],\n",
      "        [1.8241, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5532, 1.4378, 1.2707, 0.0000],\n",
      "        [0.0000, 0.7177, 0.0000, 0.4825]])\n",
      "tensor([[1.0000, 0.4135, 0.0000, 0.0000],\n",
      "        [1.8241, 1.0000, 0.0000, 0.0000],\n",
      "        [0.5532, 1.4378, 1.0000, 0.0000],\n",
      "        [0.0000, 0.7177, 0.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(4, 4)\n",
    "print(x)\n",
    "x[x<0.2] = 0\n",
    "print(x)\n",
    "# 将对角线元素设置为1\n",
    "x.fill_diagonal_(1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0caa89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 1 1 8 8 6 1 3 7 3 6 7 1 2 6 4 3 2 4 8] 4.5\n"
     ]
    }
   ],
   "source": [
    "# 统计每行的非零元素个数\n",
    "file_path =r\"C:\\Users\\yuqin\\firsttry\\data\\correlation_matrix.csv\" \n",
    "import pandas as pd\n",
    "correlation_matrix = pd.read_csv(file_path)\n",
    "correlation_matrix = correlation_matrix.iloc[0:20, 1:21].values\n",
    "correlation_matrix[abs(correlation_matrix)<0.3] = 0\n",
    "non_zero_count = (correlation_matrix != 0).sum(axis=1)-1\n",
    "non_zero_mean = non_zero_count.sum()/20\n",
    "print(non_zero_count, non_zero_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "829835f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([640, 20])\n",
      "edge_index shape: torch.Size([2, 9920])\n",
      "edge_attr shape: torch.Size([9920])\n"
     ]
    }
   ],
   "source": [
    "# 查看edge_index, edge_attr的形状\n",
    "import torch    \n",
    "from main import train_loader\n",
    "for batch in train_loader:\n",
    "    x, edge_index, edge_attr, batch_index = batch.x, batch.edge_index, batch.edge_attr, batch.batch\n",
    "    print(x.shape)\n",
    "    print(\"edge_index shape:\", edge_index.shape)\n",
    "    print(\"edge_attr shape:\", edge_attr.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd48f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "support = torch.mm(input, self.weight)\n",
    "output = torch.spmm(adj, support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ee61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x1=torch.randn(2,3)\n",
    "x2=torch.randn(3,4)\n",
    "x3=torch.mm(x1,x2)\n",
    "print(x3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569a1751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.7040075   0.28613687 -0.53040224  0.02279595  0.4063969\n",
      "  -0.782793   -0.2301002  -0.27623415 -0.6315781 ]\n",
      " [ 0.7040075   1.          0.42137244 -0.19314873 -0.27792168  0.8479348\n",
      "  -0.6741278   0.1529089  -0.20142862 -0.8085135 ]\n",
      " [ 0.28613687  0.42137244  1.0000001  -0.14398791  0.62795174 -0.05037412\n",
      "  -0.81275594 -0.03430042 -0.5579583  -0.18500037]\n",
      " [-0.53040224 -0.19314873 -0.14398791  1.         -0.37615955 -0.00227043\n",
      "   0.4423832  -0.01338059 -0.43322942  0.32943538]\n",
      " [ 0.02279595 -0.27792168  0.62795174 -0.37615955  1.0000001  -0.6730782\n",
      "  -0.41525072 -0.4422981  -0.32169095  0.45272413]\n",
      " [ 0.4063969   0.8479348  -0.05037412 -0.00227043 -0.6730782   1.0000001\n",
      "  -0.18405049  0.28268802  0.12902696 -0.7198305 ]\n",
      " [-0.782793   -0.6741278  -0.81275594  0.4423832  -0.41525072 -0.18405049\n",
      "   0.99999994  0.09099747  0.48213065  0.53532284]\n",
      " [-0.2301002   0.1529089  -0.03430042 -0.01338059 -0.4422981   0.28268802\n",
      "   0.09099747  1.          0.5582822  -0.5782256 ]\n",
      " [-0.27623415 -0.20142862 -0.5579583  -0.43322942 -0.32169095  0.12902696\n",
      "   0.48213065  0.5582822   0.99999994 -0.16929874]\n",
      " [-0.6315781  -0.8085135  -0.18500037  0.32943538  0.45272413 -0.7198305\n",
      "   0.53532284 -0.5782256  -0.16929874  0.9999999 ]]\n",
      "Sparse tensor:\n",
      "tensor(indices=tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "                        1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "                        3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5,\n",
      "                        5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,\n",
      "                        7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9,\n",
      "                        9, 9, 9, 9, 9],\n",
      "                       [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8,\n",
      "                        9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7,\n",
      "                        8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6,\n",
      "                        7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5,\n",
      "                        6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4,\n",
      "                        5, 6, 7, 8, 9]]),\n",
      "       values=tensor([ 1.0000,  0.7040,  0.2861, -0.5304,  0.0228,  0.4064,\n",
      "                      -0.7828, -0.2301, -0.2762, -0.6316,  0.7040,  1.0000,\n",
      "                       0.4214, -0.1931, -0.2779,  0.8479, -0.6741,  0.1529,\n",
      "                      -0.2014, -0.8085,  0.2861,  0.4214,  1.0000, -0.1440,\n",
      "                       0.6280, -0.0504, -0.8128, -0.0343, -0.5580, -0.1850,\n",
      "                      -0.5304, -0.1931, -0.1440,  1.0000, -0.3762, -0.0023,\n",
      "                       0.4424, -0.0134, -0.4332,  0.3294,  0.0228, -0.2779,\n",
      "                       0.6280, -0.3762,  1.0000, -0.6731, -0.4153, -0.4423,\n",
      "                      -0.3217,  0.4527,  0.4064,  0.8479, -0.0504, -0.0023,\n",
      "                      -0.6731,  1.0000, -0.1841,  0.2827,  0.1290, -0.7198,\n",
      "                      -0.7828, -0.6741, -0.8128,  0.4424, -0.4153, -0.1841,\n",
      "                       1.0000,  0.0910,  0.4821,  0.5353, -0.2301,  0.1529,\n",
      "                      -0.0343, -0.0134, -0.4423,  0.2827,  0.0910,  1.0000,\n",
      "                       0.5583, -0.5782, -0.2762, -0.2014, -0.5580, -0.4332,\n",
      "                      -0.3217,  0.1290,  0.4821,  0.5583,  1.0000, -0.1693,\n",
      "                      -0.6316, -0.8085, -0.1850,  0.3294,  0.4527, -0.7198,\n",
      "                       0.5353, -0.5782, -0.1693,  1.0000]),\n",
      "       size=(10, 10), nnz=100, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "# 将adj转换为稀疏张量\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "x1=torch.randn(10,5)\n",
    "matrix = cosine_similarity(x1)\n",
    "print(matrix)\n",
    "import numpy as np\n",
    "indices = np.array(np.nonzero(matrix))  # 获取非零元素的行列索引\n",
    "values = matrix[indices[0], indices[1]]  # 获取对应的非零值\n",
    "\n",
    "# 将 indices 转换为 torch.Tensor\n",
    "indices = torch.LongTensor(indices)\n",
    "\n",
    "# 将 values 转换为 torch.Tensor\n",
    "values = torch.FloatTensor(values)\n",
    "\n",
    "# 创建一个稀疏张量\n",
    "shape = matrix.shape  # 原数组的形状\n",
    "sparse_tensor = torch.sparse_coo_tensor(indices, values, shape)\n",
    "\n",
    "# 输出稀疏张量\n",
    "print(\"Sparse tensor:\")\n",
    "print(sparse_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将adj转化为张量\n",
    "tensor = torch.from_numpy(matrix)\n",
    "output = torch.spmm(tensor, support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1a92685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20)\n",
      "sadj 是一个 numpy.ndarray\n",
      "sadj 不是一个 numpy.ndarray\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "correlation_path=r\"C:\\Users\\yuqin\\firsttry\\data\\correlation_matrix.csv\"\n",
    "correlation_matrix = pd.read_csv(correlation_path)\n",
    "sadj = correlation_matrix.iloc[0:20, 1:21].values\n",
    "sadj[sadj < 0.3] = 0  # 将相关系数小于0.3的边删除\n",
    "print(sadj.shape)\n",
    "# 判断是否是 numpy.ndarray 类型\n",
    "if isinstance(sadj, np.ndarray):\n",
    "    print(\"sadj 是一个 numpy.ndarray\")\n",
    "else:\n",
    "    print(\"sadj 不是一个 numpy.ndarray\")\n",
    "sadj = torch.tensor(sadj, dtype=torch.float32)\n",
    "if isinstance(sadj, np.ndarray):\n",
    "    print(\"sadj 是一个 numpy.ndarray\")\n",
    "else:\n",
    "    print(\"sadj 不是一个 numpy.ndarray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20758c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8144, -2.2193, -0.4141, -0.8200, -0.4098],\n",
      "        [-1.5581,  1.1052, -1.4366,  1.6742,  0.7849],\n",
      "        [-0.7761, -0.7545, -0.8297,  0.4517,  0.6463],\n",
      "        [ 0.3189,  0.0555,  1.2401, -0.5318,  2.0426],\n",
      "        [ 0.6017,  0.5958,  0.3841, -0.8141,  0.4347]])\n",
      "tensor([[0, 4],\n",
      "        [3, 1],\n",
      "        [4, 3],\n",
      "        [4, 2],\n",
      "        [0, 1]])\n",
      "tensor([[ 1.8144,  0.0000,  0.0000,  0.0000, -0.4098],\n",
      "        [ 0.0000,  1.1052,  0.0000,  1.6742,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.4517,  0.6463],\n",
      "        [ 0.0000,  0.0000,  1.2401,  0.0000,  2.0426],\n",
      "        [ 0.6017,  0.5958,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(5,5)\n",
    "print(x)\n",
    "# 只保留每行前5个最大的值，其余的值设置为0\n",
    "_, indices = x.topk(2, dim=1)\n",
    "print(indices)\n",
    "for i in range(x.size(0)):\n",
    "    x[i][x[i] < x[i, indices[i][-1]]] = 0\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65b7db52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[640, 20], edge_index=[2, 9920], edge_attr=[9920], y=[640], batch=[640], ptr=[33])\n",
      "DataBatch(x=[620, 20], edge_index=[2, 9610], edge_attr=[9610], y=[620], batch=[620], ptr=[32])\n"
     ]
    }
   ],
   "source": [
    "from main import train_loader\n",
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "\n",
    "            # x, edge_index, batch_index, fadj, sadj = batch.x, batch.edge_index, batch.batch, batch.fadj, batch.sadj\n",
    "            # print(\"x shape:\", x.shape, \"edge_index shape:\", edge_index.shape,  \"fadj shape:\", fadj.shape, \"sadj shape:\", sadj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5dc86d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20]), Data(x=[20, 20], edge_index=[2, 310], edge_attr=[310], y=[20])]\n"
     ]
    }
   ],
   "source": [
    "from main import train_loader, batch_data_list\n",
    "\n",
    "# for batch in train_loader:\n",
    "#     x, edge_index, edge_attr, batch_index, fadj, sadj = batch.x, batch.edge_index, batch.edge_attr, batch.batch, batch.fadj, batch.sadj\n",
    "#     print(\"x shape:\", x.shape, \"edge_index shape:\", edge_index.shape,  \"fadj shape:\", fadj.shape, \"sadj shape:\", sadj.shape)\n",
    "#     break\n",
    "print(batch_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd2037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    " \n",
    "# 随机数种子\n",
    "np.random.seed(0)\n",
    " \n",
    " \n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    " \n",
    "    def __getitem__(self, index):\n",
    "        sequence, label = self.sequences[index]\n",
    "        return torch.Tensor(sequence), torch.Tensor(label)\n",
    " \n",
    " \n",
    "def calculate_mae(y_true, y_pred):\n",
    "    # 平均绝对误差\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    return mae\n",
    " \n",
    "\"\"\"\n",
    "数据定义部分\n",
    "\"\"\"\n",
    "true_data = pd.read_csv('ETTh1.csv')  # 填你自己的数据地址,自动选取你最后一列数据为特征列\n",
    " \n",
    " \n",
    "target = 'OT'  # 添加你想要预测的特征列\n",
    "test_size = 0.15  # 训练集和测试集的尺寸划分\n",
    "train_size = 0.85  # 训练集和测试集的尺寸划分\n",
    "pre_len = 4  # 预测未来数据的长度\n",
    "train_window = 32  # 观测窗口\n",
    " \n",
    "# 这里加一些数据的预处理, 最后需要的格式是pd.series\n",
    "true_data = np.array(true_data[target])\n",
    " \n",
    "# 定义标准化优化器\n",
    "scaler_train = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler_test = MinMaxScaler(feature_range=(0, 1))\n",
    " \n",
    "# 训练集和测试集划分\n",
    "train_data = true_data[:int(train_size * len(true_data))]\n",
    "test_data = true_data[-int(test_size * len(true_data)):]\n",
    "print(\"训练集尺寸:\", len(train_data))\n",
    "print(\"测试集尺寸:\", len(test_data))\n",
    " \n",
    "# 进行标准化处理\n",
    "train_data_normalized = scaler_train.fit_transform(train_data.reshape(-1, 1))\n",
    "test_data_normalized = scaler_test.fit_transform(test_data.reshape(-1, 1))\n",
    " \n",
    "# 转化为深度学习模型需要的类型Tensor\n",
    "train_data_normalized = torch.FloatTensor(train_data_normalized)\n",
    "test_data_normalized = torch.FloatTensor(test_data_normalized)\n",
    " \n",
    " \n",
    "def create_inout_sequences(input_data, tw, pre_len):\n",
    "    # 创建时间序列数据专用的数据分割器\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L - tw):\n",
    "        train_seq = input_data[i:i + tw]\n",
    "        if (i + tw + 4) > len(input_data):\n",
    "            break\n",
    "        train_label = input_data[i + tw:i + tw + pre_len]\n",
    "        inout_seq.append((train_seq, train_label))\n",
    "    return inout_seq\n",
    " \n",
    " \n",
    "# 定义训练器的的输入\n",
    "train_inout_seq = create_inout_sequences(train_data_normalized, train_window, pre_len)\n",
    "test_inout_seq = create_inout_sequences(test_data_normalized, train_window, pre_len)\n",
    " \n",
    "# 创建数据集\n",
    "train_dataset = TimeSeriesDataset(train_inout_seq)\n",
    "test_dataset = TimeSeriesDataset(test_inout_seq)\n",
    " \n",
    "# 创建 DataLoader\n",
    "batch_size = 32  # 你可以根据需要调整批量大小\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    " \n",
    " \n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_dim=1, hidden_dim=32, num_layers=1, output_dim=1, pre_len= 4):\n",
    "        super(GRU, self).__init__()\n",
    "        self.pre_len = pre_len\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # 替换 LSTM 为 GRU\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim,num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    def forward(self, x):\n",
    "        h0_gru = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    " \n",
    "        out, _ = self.gru(x, h0_gru)\n",
    " \n",
    "        out = self.dropout(out)\n",
    " \n",
    "        # 取最后 pre_len 时间步的输出\n",
    "        out = out[:, -self.pre_len:, :]\n",
    " \n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    " \n",
    " \n",
    "lstm_model = GRU(input_dim=1, output_dim=1, num_layers=2, hidden_dim=train_window, pre_len=pre_len)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.005)\n",
    "epochs = 20\n",
    "Train = True  # 训练还是预测\n",
    " \n",
    "if Train:\n",
    "    losss = []\n",
    "    lstm_model.train()  # 训练模式\n",
    "    for i in range(epochs):\n",
    "        start_time = time.time()  # 计算起始时间\n",
    "        for seq, labels in train_loader:\n",
    "            lstm_model.train()\n",
    "            optimizer.zero_grad()\n",
    " \n",
    "            y_pred = lstm_model(seq)\n",
    " \n",
    "            single_loss = loss_function(y_pred, labels)\n",
    " \n",
    "            single_loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "        losss.append(single_loss.detach().numpy())\n",
    "    torch.save(lstm_model.state_dict(), 'save_model.pth')\n",
    "    print(f\"模型已保存,用时:{(time.time() - start_time) / 60:.4f} min\")\n",
    " \n",
    " \n",
    "else:\n",
    "    # 加载模型进行预测\n",
    "    lstm_model.load_state_dict(torch.load('save_model.pth'))\n",
    "    lstm_model.eval()  # 评估模式\n",
    "    results = []\n",
    "    reals = []\n",
    "    losss = []\n",
    " \n",
    "    for seq, labels in test_loader:\n",
    "        pred = lstm_model(seq)\n",
    "        mae = calculate_mae(pred.detach().numpy(), np.array(labels))  # MAE误差计算绝对值(预测值  - 真实值)\n",
    "        losss.append(mae)\n",
    "        for j in range(batch_size):\n",
    "            for i in range(pre_len):\n",
    "                reals.append(labels[j][i][0].detach().numpy())\n",
    "                results.append(pred[j][i][0].detach().numpy())\n",
    " \n",
    "    reals = scaler_test.inverse_transform(np.array(reals).reshape(1, -1))[0]\n",
    "    results = scaler_test.inverse_transform(np.array(results).reshape(1, -1))[0]\n",
    "    print(\"模型预测结果：\", results)\n",
    "    print(\"预测误差MAE:\", losss)\n",
    " \n",
    "    plt.figure()\n",
    "    plt.style.use('ggplot')\n",
    " \n",
    "    # 创建折线图\n",
    "    plt.plot(reals, label='real', color='blue')  # 实际值\n",
    "    plt.plot(results, label='forecast', color='red', linestyle='--')  # 预测值\n",
    " \n",
    "    # 增强视觉效果\n",
    "    plt.grid(True)\n",
    "    plt.title('real vs forecast')\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('value')\n",
    "    plt.legend()\n",
    "    plt.savefig('test——results.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69d5e450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([[ 0.5534, -0.3601, -0.6340],\n",
      "        [ 0.1635,  1.5712,  0.8667],\n",
      "        [ 1.1764, -0.1071, -0.4689]]), 1, tensor([[ 1.5534, -0.3601, -0.6340],\n",
      "        [ 0.1635,  2.5712,  0.8667],\n",
      "        [ 1.1764, -0.1071,  0.5311]])), (tensor([[ 0.8329,  0.1977, -1.0800],\n",
      "        [-0.8097,  0.7092,  1.4769],\n",
      "        [ 0.8609, -0.3399, -1.0729]]), 2, tensor([[ 1.8329,  0.1977, -1.0800],\n",
      "        [-0.8097,  1.7092,  1.4769],\n",
      "        [ 0.8609, -0.3399, -0.0729]])), (tensor([[-0.1230, -0.6563, -0.6860],\n",
      "        [-1.3283, -1.0717,  1.6726],\n",
      "        [-0.0964,  0.0634, -1.2715]]), 3, tensor([[ 0.8770, -0.6563, -0.6860],\n",
      "        [-1.3283, -0.0717,  1.6726],\n",
      "        [-0.0964,  0.0634, -0.2715]])), (tensor([[-0.9171, -0.0213,  1.6839],\n",
      "        [ 1.3951, -1.6313,  0.9454],\n",
      "        [-0.9708,  1.0789,  0.7826]]), 4, tensor([[ 0.0829, -0.0213,  1.6839],\n",
      "        [ 1.3951, -0.6313,  0.9454],\n",
      "        [-0.9708,  1.0789,  1.7826]])), (tensor([[-1.0664,  0.1757, -0.7298],\n",
      "        [-1.2734,  0.7878,  1.1489],\n",
      "        [ 0.5370,  0.5216, -0.5192]]), 5, tensor([[-0.0664,  0.1757, -0.7298],\n",
      "        [-1.2734,  1.7878,  1.1489],\n",
      "        [ 0.5370,  0.5216,  0.4808]]))]\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "x1 = torch.randn(3,3)\n",
    "x2 = torch.randn(3,3)\n",
    "x3 = torch.randn(3,3)\n",
    "x4 = torch.randn(3,3)\n",
    "x5 = torch.randn(3,3)\n",
    "y1 = 1\n",
    "y2 = 2\n",
    "y3 = 3\n",
    "y4 = 4\n",
    "y5 = 5\n",
    "z1 = sadj = x1 + torch.eye(x1.size(0), dtype=torch.float32)\n",
    "z2 = sadj = x2 + torch.eye(x2.size(0), dtype=torch.float32)\n",
    "z3 = sadj = x3 + torch.eye(x3.size(0), dtype=torch.float32)\n",
    "z4 = sadj = x4 + torch.eye(x4.size(0), dtype=torch.float32)\n",
    "z5 = sadj = x5 + torch.eye(x5.size(0), dtype=torch.float32)\n",
    "list = []\n",
    "list.append((x1,y1,z1))\n",
    "list.append((x2,y2,z2))\n",
    "list.append((x3,y3,z3))\n",
    "list.append((x4,y4,z4))\n",
    "list.append((x5,y5,z5))\n",
    "print(list)\n",
    "train_data, test_data = train_test_split(list, test_size=0.2, random_state=42)\n",
    "for i in train_data:\n",
    "    x = i[2]\n",
    "    y = i[1]\n",
    "    print(x.dtype)\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57732202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.randn(3,3)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2e1b59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m MyNeuralNetwork()\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# 将模型移到GPU\u001b[39;00m\n\u001b[1;32m      4\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MyNeuralNetwork().to(device)  # 将模型移到GPU\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 假设我们有输入数据和标签\n",
    "inputs = inputs.to(device)\n",
    "labels = labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c1fc5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch \n",
    "# Specify the directory\n",
    "directory = 'CMIN/CMIN-US/price/raw/'\n",
    "# List all files in the directory\n",
    "filenames = os.listdir(directory)\n",
    "company_list = []\n",
    "for filename in filenames:\n",
    "    filename = filename[:-4]\n",
    "    company_list.append(filename)\n",
    "\n",
    "n_company =len(company_list)\n",
    "n_company\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db9022ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n"
     ]
    }
   ],
   "source": [
    "print('d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b30eb8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEM.txt', 'AAPL.txt', 'NFLX.txt', 'ABBV.txt', 'NGG.txt', 'ABT.txt', 'NKE.txt', 'ACN.txt', 'NVO.txt', 'ADBE.txt', 'NVDA.txt', 'ADP.txt', 'NVS.txt', 'AEP.txt', 'O.txt', 'AMT.txt', 'RIO.txt', 'AMZN.txt', 'RTX.txt', 'APD.txt', 'SBAC.txt', 'ASML.txt', 'SBUX.txt', 'AVGO.txt', 'SCHW.txt', 'AWK.txt', 'SHW.txt', 'BA.txt', 'SNP.txt', 'BABA.txt', 'SO.txt', 'BAC.txt', 'SPG-PJ.txt', 'BBL.txt', 'SRE.txt', 'BHP.txt', 'T.txt', 'BP.txt', 'TGT.txt', 'BRK-A.txt', 'TM.txt', 'C-PJ.txt', 'TMO.txt', 'CAT.txt', 'TMUS.txt', 'CCI.txt', 'TSLA.txt', 'CHTR.txt', 'TSM.txt', 'CMCSA.txt', 'TTE.txt', 'COP.txt', 'UL.txt', 'COST.txt', 'UNH.txt', 'CSCO.txt', 'UPS.txt', 'CTA-PB.txt', 'Unp.txt', 'CVX.txt', 'V.txt', 'D.txt', 'VALE.txt', 'DE.txt', 'VZ.txt', 'DEO.txt', 'WELL.txt', 'DHR.txt', 'WFC-PL.txt', 'DIS.txt', 'WMT.txt', 'DLR.txt', 'XEL.txt', 'DUK.txt', 'XOM.txt', 'ECL.txt', 'snap.txt', 'EL.txt', 'ENB.txt', 'EQIX.txt', 'EQNR.txt', 'EXC.txt', 'FB.txt', 'FCX.txt', 'GE.txt', 'GOOG.txt', 'HD.txt', 'HON.txt', 'JD.txt', 'JNJ.txt', 'JPM.txt', 'KO.txt', 'LLY.txt', 'LOW.txt', 'MA.txt', 'MCD.txt', 'MMM.txt', 'MS.txt', 'MSFT.txt', 'NEE.txt', 'ORCL.txt', 'PEP.txt', 'PFE.txt', 'PG.txt', 'PLD.txt', 'PM.txt', 'PSA.txt', 'PTR.txt', 'PYPL.txt', 'RDS-B.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "## 获取股票数据 \n",
    "folder_path = '/root/firsttry/CMIN/CMIN-US/price/processed/'\n",
    "\n",
    "## 获取文件夹中所有文件的文件名\n",
    "file_list = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea46de3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1002, 6)\n",
      "0 NEM\n",
      "1 AAPL\n",
      "2 NFLX\n",
      "3 ABBV\n",
      "4 NGG\n",
      "5 ABT\n",
      "6 NKE\n",
      "7 ACN\n",
      "8 NVO\n",
      "9 ADBE\n",
      "10 NVDA\n",
      "11 ADP\n",
      "12 NVS\n",
      "13 AEP\n",
      "14 O\n",
      "15 AMT\n",
      "16 RIO\n",
      "17 AMZN\n",
      "18 RTX\n",
      "19 APD\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from model import *\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 设定数据量\n",
    "n_company = 20\n",
    "num_days = 1002  # 股价天数\n",
    "num_features = 6  # 每个时间点有6个特征（如开盘价、收盘价等）\n",
    "\n",
    "## 获取股票数据 \n",
    "folder_path = '/root/firsttry/CMIN/CMIN-US/price/processed/'\n",
    "\n",
    "## 获取文件夹中所有文件的文件名\n",
    "file_list = [f for f in os.listdir(folder_path) if f.endswith('.txt')]\n",
    "\n",
    "\n",
    "## 初始化一个空的DataFrame用于存储合并后的数据\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "##迭代每个文件，读取文件并添加文件名列\n",
    "for file_name in file_list:\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    df = pd.read_csv(file_path, sep='\\t', header=None, names=['dt', 'open', 'high', 'low', 'close', 'adj close', 'volume'])  # 读取文件\n",
    "    df['code'] = file_name[0:-4]  # 在DataFrame中添加一列，用于存储文件名\n",
    "    all_data = pd.concat([all_data, df], ignore_index=True)  # 合并当前文件数据到总数据\n",
    "# all_data = all_data.to(device)\n",
    "\n",
    "# 保存合并后的DataFrame为pkl文件 (num_stock*num_features, index+file_name+num_features+)\n",
    "output_path = 'my_data.pkl'\n",
    "all_data.to_pickle(output_path)\n",
    "\n",
    "#  初始化一个空的三维数组，用于存储股价数据\n",
    "stock_data = np.zeros((n_company, num_days, num_features))\n",
    "print(stock_data.shape)\n",
    "#  将数据加载到stock_data中\n",
    "for i, stock_code in enumerate(all_data['code'].unique()):\n",
    "    print(i,stock_code)\n",
    "    stock_data[i] = all_data[all_data['code'] == stock_code].iloc[:, 1:7].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f85325a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3636, 0.0000, 0.0000, 0.0636, 0.0636, 0.0636, 0.0000, 0.0636, 0.0636,\n",
      "         0.0000, 0.0636, 0.1273, 0.0000, 0.0000, 0.0636, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0636],\n",
      "        [0.0000, 0.8163, 0.1837, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.1837, 0.8163, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0700, 0.0000, 0.0000, 0.4000, 0.0600, 0.1100, 0.0000, 0.0700, 0.0800,\n",
      "         0.0000, 0.0700, 0.0700, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0700],\n",
      "        [0.0714, 0.0000, 0.0000, 0.0612, 0.4082, 0.0714, 0.0000, 0.0714, 0.0918,\n",
      "         0.0000, 0.0714, 0.0918, 0.0000, 0.0000, 0.0612, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0769, 0.0000, 0.0000, 0.1209, 0.0769, 0.4396, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0769, 0.0000, 0.0000, 0.0000, 0.1319, 0.0000, 0.0000,\n",
      "         0.0000, 0.0769],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7547, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.2453, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1148, 0.0000, 0.0000, 0.1148, 0.1148, 0.0000, 0.0000, 0.6557, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0707, 0.0000, 0.0000, 0.0808, 0.0909, 0.0000, 0.0000, 0.0000, 0.4040,\n",
      "         0.0000, 0.0707, 0.0707, 0.0000, 0.0000, 0.1414, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0707],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.6349, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1111, 0.0000,\n",
      "         0.1429, 0.1111],\n",
      "        [0.0814, 0.0000, 0.0000, 0.0814, 0.0814, 0.0000, 0.0000, 0.0000, 0.0814,\n",
      "         0.0000, 0.4651, 0.1279, 0.0000, 0.0000, 0.0814, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.1373, 0.0000, 0.0000, 0.0686, 0.0882, 0.0686, 0.0000, 0.0000, 0.0686,\n",
      "         0.0000, 0.1078, 0.3922, 0.0000, 0.0000, 0.0686, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2453, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.7547, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.7143, 0.0000, 0.1607, 0.0000, 0.0000,\n",
      "         0.0000, 0.1250],\n",
      "        [0.0864, 0.0000, 0.0000, 0.0000, 0.0741, 0.0000, 0.0000, 0.0000, 0.1728,\n",
      "         0.0000, 0.0864, 0.0864, 0.0000, 0.0000, 0.4938, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1538, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.1154, 0.0000, 0.5128, 0.0000, 0.0000,\n",
      "         0.0897, 0.1282],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0877, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5013, 0.2481,\n",
      "         0.1629, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2964, 0.5988,\n",
      "         0.1048, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1184, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0921, 0.1711, 0.0921,\n",
      "         0.5263, 0.0000],\n",
      "        [0.0761, 0.0000, 0.0000, 0.0761, 0.0000, 0.0761, 0.0000, 0.0000, 0.0761,\n",
      "         0.0761, 0.0000, 0.0000, 0.0000, 0.0761, 0.0000, 0.1087, 0.0000, 0.0000,\n",
      "         0.0000, 0.4348]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "\n",
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize  matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(axis = 1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = np.diag(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    return mx\n",
    "\n",
    "# 获取结构邻接矩阵\n",
    "n_company = 20\n",
    "correlation_path=\"/root/firsttry/data/topology_correlation_matrix.csv\"\n",
    "correlation_matrix = pd.read_csv(correlation_path)\n",
    "sadj = correlation_matrix.iloc[0:n_company, 1:(n_company+1)].values\n",
    "sadj[sadj < 0.3] = 0  # 将相关系数小于0.3的边删除\n",
    "\n",
    "\"\"\"\n",
    "sadj的tensor化正确\n",
    "\"\"\"\n",
    "sadj = torch.tensor(sadj, dtype=torch.float32) \n",
    "sadj = sadj + sadj.T.mul(sadj.T > sadj) - sadj.mul(sadj.T > sadj)\n",
    "sadj = normalize(sadj + torch.eye(sadj.size(0), dtype=torch.float32))\n",
    "sadj = torch.from_numpy(sadj)\n",
    "print(sadj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3533db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x1 = torch.randn(3,4).to(\"cuda\")\n",
    "x1 = x1.cpu()\n",
    "print(x1.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4ed5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n",
      "/root/firsttry/data/generate_data.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fadj = torch.tensor(fadj, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/100, Loss: 1.0155485020558925\n",
      "Epoch 2/100, Loss: 1.0111863929896978\n",
      "Epoch 3/100, Loss: 1.0109945485925977\n",
      "Epoch 4/100, Loss: 1.0108348470584603\n",
      "Epoch 5/100, Loss: 1.0107020746892805\n",
      "Epoch 6/100, Loss: 1.0108118383652844\n",
      "Epoch 7/100, Loss: 1.0106787442069525\n",
      "Epoch 8/100, Loss: 1.0105292524169585\n",
      "Epoch 9/100, Loss: 1.011040996000835\n",
      "Epoch 10/100, Loss: 1.0106576097808826\n",
      "Epoch 11/100, Loss: 1.0110725506713056\n",
      "Epoch 12/100, Loss: 1.0109955331512317\n",
      "Epoch 13/100, Loss: 1.0112647930338126\n",
      "Epoch 14/100, Loss: 1.0112455816405594\n",
      "Epoch 15/100, Loss: 1.0107349956633558\n",
      "Epoch 16/100, Loss: 1.0109471541348916\n",
      "Epoch 17/100, Loss: 1.0109370497001964\n",
      "Epoch 18/100, Loss: 1.0108238108788326\n",
      "Epoch 19/100, Loss: 1.0108198981945682\n",
      "Epoch 20/100, Loss: 1.0109198952651328\n",
      "Epoch 21/100, Loss: 1.0108005811406928\n",
      "Epoch 22/100, Loss: 1.0110028523406025\n",
      "Epoch 23/100, Loss: 1.0111469870255252\n",
      "Epoch 24/100, Loss: 1.0112166470830228\n",
      "Epoch 25/100, Loss: 1.0108478898550295\n",
      "Epoch 26/100, Loss: 1.0106879539977593\n",
      "Epoch 27/100, Loss: 1.0107764334198397\n",
      "Epoch 28/100, Loss: 1.0112066860221753\n",
      "Epoch 29/100, Loss: 1.0112237920521931\n",
      "Epoch 30/100, Loss: 1.0112054213691668\n",
      "Epoch 31/100, Loss: 1.011201669365927\n",
      "Epoch 32/100, Loss: 1.0107601761343372\n",
      "Epoch 33/100, Loss: 1.0106601885834317\n",
      "Epoch 34/100, Loss: 1.0109459441511115\n",
      "Epoch 35/100, Loss: 1.0110939736958522\n",
      "Epoch 36/100, Loss: 1.010916906049487\n",
      "Epoch 37/100, Loss: 1.0108812128282656\n",
      "Epoch 38/100, Loss: 1.0108753553811152\n",
      "Epoch 39/100, Loss: 1.010862812774766\n",
      "Epoch 40/100, Loss: 1.0107423221324658\n",
      "Epoch 41/100, Loss: 1.0110269607252376\n",
      "Epoch 42/100, Loss: 1.011099839096616\n",
      "Epoch 43/100, Loss: 1.011240304550927\n",
      "Epoch 44/100, Loss: 1.0112936298131563\n",
      "Epoch 45/100, Loss: 1.0107495417877748\n",
      "Epoch 46/100, Loss: 1.0108163789816342\n",
      "Epoch 47/100, Loss: 1.0108390691648623\n",
      "Epoch 48/100, Loss: 1.0108602031828111\n",
      "Epoch 49/100, Loss: 1.011093252531852\n",
      "Epoch 50/100, Loss: 1.0111326641527711\n",
      "Epoch 51/100, Loss: 1.0108716927563688\n",
      "Epoch 52/100, Loss: 1.0110933261597232\n",
      "Epoch 53/100, Loss: 1.0109621427668507\n",
      "Epoch 54/100, Loss: 1.0113296009552706\n",
      "Epoch 55/100, Loss: 1.0108777127021058\n",
      "Epoch 56/100, Loss: 1.01073261043828\n",
      "Epoch 57/100, Loss: 1.0107802331352689\n",
      "Epoch 58/100, Loss: 1.0107142859346168\n",
      "Epoch 59/100, Loss: 1.0109772768749552\n",
      "Epoch 60/100, Loss: 1.0109619684469928\n",
      "Epoch 61/100, Loss: 1.0108852764176335\n",
      "Epoch 62/100, Loss: 1.0107962427340496\n",
      "Epoch 63/100, Loss: 1.0111674331982803\n",
      "Epoch 64/100, Loss: 1.0113140882200495\n",
      "Epoch 65/100, Loss: 1.0107864872570251\n",
      "Epoch 66/100, Loss: 1.0110895707396566\n",
      "Epoch 67/100, Loss: 1.010908398829448\n",
      "Epoch 68/100, Loss: 1.0110555471460911\n",
      "Epoch 69/100, Loss: 1.0106586441777314\n",
      "Epoch 70/100, Loss: 1.010857566887406\n",
      "Epoch 71/100, Loss: 1.0109789326597172\n",
      "Epoch 72/100, Loss: 1.0108686397884301\n",
      "Epoch 73/100, Loss: 1.010904851617517\n",
      "Epoch 74/100, Loss: 1.0110519125203419\n",
      "Epoch 75/100, Loss: 1.0109573285196238\n",
      "Epoch 76/100, Loss: 1.011166962644287\n",
      "Epoch 77/100, Loss: 1.0112837496077178\n",
      "Epoch 78/100, Loss: 1.0107281776133237\n",
      "Epoch 79/100, Loss: 1.010869268541503\n",
      "Epoch 80/100, Loss: 1.0108867838314384\n",
      "Epoch 81/100, Loss: 1.010836435783251\n",
      "Epoch 82/100, Loss: 1.010850169324571\n",
      "Epoch 83/100, Loss: 1.0109962830308137\n",
      "Epoch 84/100, Loss: 1.0110133792991471\n",
      "Epoch 85/100, Loss: 1.010753843454039\n",
      "Epoch 86/100, Loss: 1.0108011752272108\n",
      "Epoch 87/100, Loss: 1.0116013790486724\n",
      "Epoch 88/100, Loss: 1.010888913814809\n",
      "Epoch 89/100, Loss: 1.0110361882123597\n",
      "Epoch 90/100, Loss: 1.0106853723288722\n",
      "Epoch 91/100, Loss: 1.011142063748305\n",
      "Epoch 92/100, Loss: 1.0110003116024529\n",
      "Epoch 93/100, Loss: 1.0108557718289886\n",
      "Epoch 94/100, Loss: 1.0110942753019987\n",
      "Epoch 95/100, Loss: 1.0109925335569747\n",
      "Epoch 96/100, Loss: 1.0111035061490004\n",
      "Epoch 97/100, Loss: 1.0106890943921676\n",
      "Epoch 98/100, Loss: 1.011035615015941\n",
      "Epoch 99/100, Loss: 1.011267661160914\n",
      "Epoch 100/100, Loss: 1.0111757748588255\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m loss_values, pred_values, target_values\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss_values\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 绘制训练时的损失曲线\u001b[39;00m\n",
      "File \u001b[0;32m~/firsttry/main.py:154\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[1;32m    153\u001b[0m loss_values \u001b[38;5;241m=\u001b[39m train_model(model, train_data, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m--> 154\u001b[0m loss_values \u001b[38;5;241m=\u001b[39m \u001b[43mloss_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m()\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# 绘制训练时的损失曲线\u001b[39;00m\n\u001b[1;32m    157\u001b[0m epochs_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from main import loss_values, pred_values, target_values\n",
    "for t in loss_values:\n",
    "    print(t.)\n",
    "print(loss_values.device)\n",
    "\n",
    "# 绘制训练时的损失曲线\n",
    "epochs_range = range(100)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs_range, loss_values, marker='o', linestyle='-', color='b', label='Loss')\n",
    "plt.title('Training Loss Curve', fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('training_loss_curve.png')\n",
    "\n",
    "# 测试模型\n",
    "\n",
    "pred_values, target_values = pred_values.cpu(), target_values.cpu()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f23c2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc8ebca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original GPU Tensor List:\n",
      "tensor([1, 2, 3], device='cuda:0') cuda:0\n",
      "tensor([4, 5, 6], device='cuda:0') cuda:0\n",
      "\n",
      "Migrated CPU Tensor List:\n",
      "tensor([1, 2, 3]) cpu\n",
      "tensor([4, 5, 6]) cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 模拟 GPU 上的 Tensor List\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tensor_list_gpu = [torch.tensor([1, 2, 3], device=device), torch.tensor([4, 5, 6], device=device)]\n",
    "\n",
    "# 将 GPU Tensor 迁移到 CPU\n",
    "tensor_list_cpu = [t.cpu() for t in tensor_list_gpu]\n",
    "\n",
    "# 查看结果\n",
    "print(\"Original GPU Tensor List:\")\n",
    "for t in tensor_list_gpu:\n",
    "    print(t, t.device)\n",
    "\n",
    "print(\"\\nMigrated CPU Tensor List:\")\n",
    "for t in tensor_list_cpu:\n",
    "    print(t, t.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d04fbb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def han():\n",
    "    print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc90b83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([110, 64]) torch.Size([110, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# GRU Model\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_1, _ = self.gru(x)\n",
    "        # Take the output of the last time step\n",
    "        out_2 = self.fc(out_1)  \n",
    "        return out_1,out_2\n",
    "\n",
    "# Hyperparameters\n",
    "input_size = 20  # Each node feature is 20-dimensional\n",
    "hidden_size = 64\n",
    "output_size = 1  # Output for each node (or aggregated output)\n",
    "num_layers = 2\n",
    "learning_rate = 0.001\n",
    "num_nodes = 110  # Number of nodes (example size)\n",
    "epochs = 50\n",
    "x = torch.randn(110,20)\n",
    "y = torch.rand(110)\n",
    "\n",
    "model = GRUModel(input_size, hidden_size, output_size, num_layers)\n",
    "a,b = model.forward(x)\n",
    "print(a.shape, b.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f73f44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0530, -0.3955, -0.8346,  0.5348,  0.2964, -0.7354,  0.7210, -1.1561,\n",
      "         0.4831,  0.0539,  0.9434, -0.9038, -1.0901,  0.1797,  1.5278, -0.5643,\n",
      "         0.0918,  0.3521,  1.1762, -0.5371]) tensor([-1.2511,  0.3673,  1.6838, -0.0270,  1.1019, -0.6602, -0.1400,  0.3115,\n",
      "        -0.2202, -0.1501, -1.0527,  1.1789, -1.8414,  1.4203,  1.8792,  1.3221,\n",
      "         0.9199,  0.6296,  0.3717,  0.3932])\n",
      "tensor(0.0338) tensor(0.9299)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.randn(110,20)\n",
    "y = torch.rand(110)\n",
    "train_data = []\n",
    "train_data.append(x)\n",
    "train_data.append(y)\n",
    "for i in train_data:\n",
    "    x, y= i[0], i[1]\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05643431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.randn(15,20)\n",
    "y = torch.randn(15,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3015c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "folder_path = '/root/firsttry/CMIN/CMIN-US/price/processed/'\n",
    "file_list = [f for f in os.listdir(folder_path) if f.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4806c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVDA.txt'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a4c2c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(folder_path, file_list[10]), sep='\\t', header=None, names=['dt', 'open', 'high', 'low', 'close', 'adj close', 'volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe40814c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>0.065814</td>\n",
       "      <td>0.042497</td>\n",
       "      <td>0.071178</td>\n",
       "      <td>0.047558</td>\n",
       "      <td>0.065814</td>\n",
       "      <td>91470400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.057129</td>\n",
       "      <td>0.020356</td>\n",
       "      <td>0.043877</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>58326800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>-0.007277</td>\n",
       "      <td>-0.005228</td>\n",
       "      <td>-0.007570</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>58012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>0.030641</td>\n",
       "      <td>0.028993</td>\n",
       "      <td>0.037297</td>\n",
       "      <td>0.035532</td>\n",
       "      <td>0.030641</td>\n",
       "      <td>88121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>-0.005244</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>49700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>-0.020643</td>\n",
       "      <td>-0.101663</td>\n",
       "      <td>-0.071823</td>\n",
       "      <td>-0.011853</td>\n",
       "      <td>-0.020643</td>\n",
       "      <td>71375800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>-0.002950</td>\n",
       "      <td>-0.024299</td>\n",
       "      <td>-0.026900</td>\n",
       "      <td>-0.022154</td>\n",
       "      <td>-0.002950</td>\n",
       "      <td>46184700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>0.048920</td>\n",
       "      <td>0.039150</td>\n",
       "      <td>0.034679</td>\n",
       "      <td>0.009431</td>\n",
       "      <td>0.048920</td>\n",
       "      <td>52438500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>0.018221</td>\n",
       "      <td>0.014938</td>\n",
       "      <td>0.038247</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>39518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>0.029905</td>\n",
       "      <td>0.017053</td>\n",
       "      <td>0.034518</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>34262400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1002 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dt      open      high       low     close  adj close    volume\n",
       "0     2018-01-03  0.065814  0.042497  0.071178  0.047558   0.065814  91470400\n",
       "1     2018-01-04  0.005271  0.057129  0.020356  0.043877   0.005271  58326800\n",
       "2     2018-01-05  0.008474 -0.007277 -0.005228 -0.007570   0.008474  58012400\n",
       "3     2018-01-08  0.030641  0.028993  0.037297  0.035532   0.030641  88121600\n",
       "4     2018-01-09 -0.000270  0.008258 -0.005244  0.000274  -0.000270  49700000\n",
       "...          ...       ...       ...       ...       ...        ...       ...\n",
       "997   2021-12-17 -0.020643 -0.101663 -0.071823 -0.011853  -0.020643  71375800\n",
       "998   2021-12-20 -0.002950 -0.024299 -0.026900 -0.022154  -0.002950  46184700\n",
       "999   2021-12-21  0.048920  0.039150  0.034679  0.009431   0.048920  52438500\n",
       "1000  2021-12-22  0.011178  0.018221  0.014938  0.038247   0.011178  39518400\n",
       "1001  2021-12-23  0.008163  0.029905  0.017053  0.034518   0.008163  34262400\n",
       "\n",
       "[1002 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e599902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置图形大小\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 绘制 'close' 列的直方图\n",
    "plt.hist(df['close'], bins=10, alpha=0.5, label='Close', color='blue', edgecolor='black')\n",
    "\n",
    "# 绘制 'adj close' 列的直方图\n",
    "plt.hist(df['adj close'], bins=10, alpha=0.5, label='Adj Close', color='red', edgecolor='black')\n",
    "\n",
    "# 添加标题和标签\n",
    "plt.title('Distribution of Close and Adjusted Close')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# 添加图例\n",
    "plt.legend()\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae480a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = '/root/firsttry/CMIN/CMIN-US/price/raw/AAPL.csv'\n",
    "df_raw = pd.read_csv(p1)\n",
    "p2 = '/root/firsttry/CMIN/CMIN-US/price/processed/AAPL.txt'\n",
    "df_prod = pd.read_csv(p2, sep='\\t', header=None, names=['dt', 'open', 'high', 'low', 'close', 'adj close', 'volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78b4315e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              NaN\n",
       "1        43.064999\n",
       "2        43.057499\n",
       "3        43.257500\n",
       "4        43.750000\n",
       "           ...    \n",
       "1003    176.279999\n",
       "1004    180.330002\n",
       "1005    179.289993\n",
       "1006    179.380005\n",
       "1007    178.199997\n",
       "Name: Close, Length: 1008, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['Close'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12012f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            NaN\n",
       "1      -0.000174\n",
       "2       0.004645\n",
       "3       0.011385\n",
       "4      -0.003714\n",
       "          ...   \n",
       "1003    0.022975\n",
       "1004   -0.005767\n",
       "1005    0.000502\n",
       "1006   -0.006578\n",
       "1007   -0.003535\n",
       "Name: Close, Length: 1008, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_raw['Close'] - df_raw['Close'].shift(1)) / df_raw['Close'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e960a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.013928</td>\n",
       "      <td>0.013059</td>\n",
       "      <td>0.015952</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>118071600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-04</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>-0.006187</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>89738400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>0.010953</td>\n",
       "      <td>0.005637</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>94640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>-0.003714</td>\n",
       "      <td>0.005247</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>-0.003714</td>\n",
       "      <td>82271200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>-0.003132</td>\n",
       "      <td>-0.002990</td>\n",
       "      <td>-0.000115</td>\n",
       "      <td>86336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>-0.006502</td>\n",
       "      <td>-0.052153</td>\n",
       "      <td>-0.042343</td>\n",
       "      <td>-0.006208</td>\n",
       "      <td>-0.006502</td>\n",
       "      <td>195432700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>-0.008122</td>\n",
       "      <td>-0.009710</td>\n",
       "      <td>-0.016660</td>\n",
       "      <td>-0.013142</td>\n",
       "      <td>-0.008122</td>\n",
       "      <td>107499100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>0.019087</td>\n",
       "      <td>0.019491</td>\n",
       "      <td>0.015359</td>\n",
       "      <td>0.009913</td>\n",
       "      <td>0.019087</td>\n",
       "      <td>91185900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>0.015319</td>\n",
       "      <td>0.008627</td>\n",
       "      <td>0.015358</td>\n",
       "      <td>0.017916</td>\n",
       "      <td>0.015319</td>\n",
       "      <td>92135300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.016239</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>0.018124</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>68227500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1002 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              dt      open      high       low     close  adj close     volume\n",
       "0     2018-01-03 -0.000174  0.013928  0.013059  0.015952  -0.000174  118071600\n",
       "1     2018-01-04  0.004645  0.000058 -0.006187  0.000698   0.004645   89738400\n",
       "2     2018-01-05  0.011385  0.005216  0.010953  0.005637   0.011385   94640000\n",
       "3     2018-01-08 -0.003714  0.005247  0.001369  0.005085  -0.003714   82271200\n",
       "4     2018-01-09 -0.000115  0.001147 -0.003132 -0.002990  -0.000115   86336000\n",
       "...          ...       ...       ...       ...       ...        ...        ...\n",
       "997   2021-12-17 -0.006502 -0.052153 -0.042343 -0.006208  -0.006502  195432700\n",
       "998   2021-12-20 -0.008122 -0.009710 -0.016660 -0.013142  -0.008122  107499100\n",
       "999   2021-12-21  0.019087  0.019491  0.015359  0.009913   0.019087   91185900\n",
       "1000  2021-12-22  0.015319  0.008627  0.015358  0.017916   0.015319   92135300\n",
       "1001  2021-12-23  0.003644  0.016239  0.005630  0.018124   0.003644   68227500\n",
       "\n",
       "[1002 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace0c4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firsttry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
