{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working dir: /home/yuheng/mydata_mgmt/nerv_ml/tools\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "print('working dir:', os.getcwd())\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import datetime\n",
    "\n",
    "from feature_utils import ema, p_change, zscore, las, featclip, sanitise\n",
    "\n",
    "raw_data_path = '/mnt/datassd2/crypto/15minbar'  \n",
    "data_save_path = '/mnt/datassd2/crypto/dl_data/'\n",
    "df = pl.scan_parquet(raw_data_path).collect()\n",
    "\n",
    "# 实盘：结合Currency_picking.ipynb 筛选了近期活跃的symbol\n",
    "used_cols = ['DOTUSDT', 'SEIUSDT', 'TRXUSDT', 'AUCTIONUSDT', 'ACHUSDT', 'INJUSDT', 'ARBUSDT', 'XRPUSDT', 'APTUSDT', '1000BONKUSDT', 'ARKUSDT', 'DOGEUSDT', 'AAVEUSDT', 'CAKEUSDT', 'UNIUSDT', 'GALAUSDT', 'ARKMUSDT', '1000SHIBUSDT', 'JTOUSDT', 'NEARUSDT', 'ETCUSDT', 'CRVUSDT', 'XLMUSDT', 'RUNEUSDT', 'ETHUSDT', 'SANDUSDT', 'FILUSDT', 'APEUSDT', 'LDOUSDT', 'AVAXUSDT', 'ZENUSDT', 'FETUSDT', 'BAKEUSDT', 'EOSUSDT', 'BNBUSDT', 'ORDIUSDT', 'MKRUSDT', 'SUIUSDT', '1000SATSUSDT', 'BTCUSDT', 'BCHUSDT', 'ALGOUSDT', 'HBARUSDT', 'OPUSDT', '1000FLOKIUSDT', 'ADAUSDT', 'ATOMUSDT', 'WLDUSDT', 'TIAUSDT', '1000PEPEUSDT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实盘需要cut最新数据\n",
    "df = df.filter(pl.col('datetime') > datetime.datetime(2024, 1, 1))\n",
    "df = df.sort(by='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['symbol'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pldf = df.with_columns(\n",
    "    ema('close', 100).over('symbol').alias('ema'),\n",
    "    p_change('close', 1).over('symbol').alias('p_change'),\n",
    "    zscore('close', 100).over('symbol').alias('zscore'),\n",
    "    ema('amount', 100).over('symbol').alias('ema_amt'),\n",
    "    p_change('amount', 1).over('symbol').alias('p_change_amt'),\n",
    "    zscore('amount', 100).over('symbol').alias('zscore_amt')\n",
    "    )\n",
    "\n",
    "pldf = raw_pldf.filter(pl.col('amount') > 0)\n",
    "\n",
    "feats = ['ema', 'p_change', 'zscore', 'ema_amt', 'p_change_amt', 'zscore_amt']\n",
    "cols = feats + las + ['symbol', 'datetime', 'date', 'close']\n",
    "pldf = pldf.select(cols)\n",
    "pldf = pldf.unique(subset=[\"symbol\", \"datetime\"], maintain_order=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pldf = pldf.filter(pl.col('symbol').is_in(used_cols))\n",
    "\n",
    "pldf = pldf.drop_nulls()\n",
    "\n",
    "pldf = pldf.with_columns(\n",
    "    pl.concat_list(feats).alias(\"feats\")\n",
    ")\n",
    "pivot_feats = pldf.pivot(on=\"symbol\",index=\"datetime\", values=\"feats\", maintain_order=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存数据\n",
    "\n",
    "1. eod_data(cs_data)\n",
    "- 处理 eod_data (S,T,F) = (n_stock, n_datetime, n_feats)  \n",
    "- 维护一个字典，映射 S,T,F 到对应的股票代码/日期/特征，后续预测值通过这个字典可以反向映射回原dataframe\n",
    "\n",
    "2. mask_data\n",
    "- 把eod == null的处理为mask\n",
    "\n",
    "3. gt_data(return_data)\n",
    "- 取la15存起来就行\n",
    "4. extra_data 其他数据\n",
    "- symbols 顺序\n",
    "- dt 顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_symbols = pivot_feats.columns\n",
    "exp_symbols.remove('datetime')\n",
    "exp_dt = pivot_feats['datetime']\n",
    "extra_data = {\n",
    "    'symbols': exp_symbols,\n",
    "    'dt': exp_dt.to_list()\n",
    "}\n",
    "\n",
    "pivot_feats = pivot_feats.drop('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task2. 得到mask_data\n",
    "mask_data = pivot_feats.with_columns(\n",
    "    pl.col(s).is_null().not_() for s in exp_symbols\n",
    ").to_numpy()\n",
    "mask_data = mask_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 填充null\n",
    "pivot_feats = pivot_feats.with_columns(\n",
    "    pl.col(s).fill_null([0.] * len(feats)) for s in exp_symbols\n",
    ")\n",
    "# task1. 得到cs_feats_data, \n",
    "feats_numpy = pivot_feats.to_numpy()\n",
    "feats_array = np.array([np.stack(sublist, axis=1) for sublist in feats_numpy])\n",
    "feats_array = feats_array.transpose(2, 0, 1)   # shape: (n_symbols, n_T,  n_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 39308, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task3 得到la_data\n",
    "la_data =  pldf.pivot(on=\"symbol\",index=\"datetime\", values=\"la60\", maintain_order=True)\n",
    "la_data = la_data.drop('datetime')\n",
    "la_array = la_data.fill_null(0.).to_numpy()\n",
    "la_array = la_array.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_array.shape: (50, 39308, 6)\n",
      "mask_data.shape: (50, 39308)\n",
      "la15_array.shape: (50, 39308)\n"
     ]
    }
   ],
   "source": [
    "print('feats_array.shape:', feats_array.shape)\n",
    "print('mask_data.shape:', mask_data.shape)\n",
    "print('la15_array.shape:', la_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to: /mnt/datassd2/crypto/dl_data/stock_mix_data\n"
     ]
    }
   ],
   "source": [
    "dataset_path = data_save_path + 'stock_mix_data'\n",
    "# mkdir\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "print('save to:', dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(os.path.join(dataset_path, \"cs_data.pkl\"), 'wb') as f:\n",
    "    pickle.dump(feats_array, f)\n",
    "with open(os.path.join(dataset_path, \"mask_data.pkl\"), 'wb') as f:\n",
    "    pickle.dump(mask_data, f)\n",
    "with open(os.path.join(dataset_path, \"la15_data.pkl\"), 'wb') as f:\n",
    "    pickle.dump(la_array, f)\n",
    "with open(os.path.join(dataset_path, \"extra_data.pkl\"), 'wb') as f:\n",
    "    pickle.dump(extra_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extra_data.keys():  dict_keys(['symbols', 'dt'])\n",
      "len(extra_data['dt']):  39308\n",
      "len(extra_data['symbols']):  50\n"
     ]
    }
   ],
   "source": [
    "print('extra_data.keys(): ', extra_data.keys())\n",
    "print('len(extra_data[\\'dt\\']): ', len(extra_data['dt']))\n",
    "print('len(extra_data[\\'symbols\\']): ', len(extra_data['symbols']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预处理MLP用的截面数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import polars as pl\n",
    "\n",
    "df = pl.scan_parquet(raw_data_path)\n",
    "df = df.filter(pl.col('datetime') > datetime.datetime(2024, 1, 1))\n",
    "df = df.sort(by='datetime')\n",
    "\n",
    "las = ['la1', 'la2', 'la5', 'la10', 'la15', 'la30', 'la60', 'la120', 'la180', 'la240', 'la300', 'la360']\n",
    "df = df.with_columns([featclip(pl.col(la)).alias(la) for la in las])\n",
    "df = df.with_columns(ema('close', 100).over('symbol').alias('ema'),)\n",
    "df = df.collect().to_pandas()\n",
    "df.drop_duplicates(subset=['datetime', 'symbol'], keep='first', inplace=True)\n",
    "factors_df = df.pivot(index='datetime', columns='symbol', values='ema')\n",
    "la_df = df.pivot(index='datetime', columns='symbol', values='la240')\n",
    "factors_df.fillna(0, inplace=True)\n",
    "la_df.fillna(0, inplace=True)\n",
    "factors_df_top50 = factors_df[used_cols].copy()\n",
    "la_df_top50 = la_df[used_cols].copy()\n",
    "X = factors_df_top50\n",
    "y = la_df_top50\n",
    "\n",
    "exp_symbols = X.columns\n",
    "exp_dt = X.index.values\n",
    "extra_data = {\n",
    "    'symbols': exp_symbols,\n",
    "    'dt': exp_dt\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save to: /mnt/datassd2/crypto/dl_data/cs_dataset\n"
     ]
    }
   ],
   "source": [
    "dataset_path = data_save_path + 'cs_dataset'\n",
    "# mkdir\n",
    "if not os.path.exists(dataset_path):\n",
    "    os.makedirs(dataset_path)\n",
    "print('save to:', dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_parquet(os.path.join(dataset_path, \"X.parquet\"))\n",
    "y.to_parquet(os.path.join(dataset_path, \"y.parquet\"))\n",
    "with open(os.path.join(dataset_path, \"extra_data.pkl\"), 'wb') as f:\n",
    "    pickle.dump(extra_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_parquet(os.path.join(dataset_path, \"X.parquet\")).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39455, 50)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39455, 50)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
